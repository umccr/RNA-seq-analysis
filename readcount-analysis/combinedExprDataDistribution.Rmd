---
title: "Read count data processing"
author: "UMCCR"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    keep_md: yes
    code_download: true
    code_folding: hide
    theme: readable
    css: combinedExprDataDistribution.css
    toc: true
    toc_float: true
  rmdformats::material:
    highlight: kate
params:
  input_dir: '/Library/WebServer/Documents/PIEdb/piedb_backoffice/data/expr_data_integration/datasets_prep/TCGA-PAAD_dataset'
  datasets: '/Library/WebServer/Documents/PIEdb/piedb_backoffice/data/expr_data_integration/datasets_prep/TCGA-PAAD_dataset/TCGA_PAAD_datasets_list.txt'
  report_dir: '/Library/WebServer/Documents/PIEdb/piedb_backoffice/data/expr_data_integration/datasets_prep/TCGA-PAAD_dataset'
  transform: 'TPM'
  norm: 'quantile'
  batch_rm: TRUE
  filter: TRUE
  log: TRUE
  genes: 'KRAS,MKI67,TP53,PTEN,SMAD4,BRCA1,BRCA2,CDKN2A,CDKN2B,BRAF'
  top_genes: 400
  ensembl: TRUE
  samples: 'TCGA-3A-A9I9-01A-11R-A38C-07'
  results_name: 'test'
  scaling: 'gene-wise'
  ref_data_dir: '../data'
  ensembl_version: 75
  hide_code_btn: TRUE
---

The aim of this report is to investigate changes to the read count data at various post-processing steps and to illustrate data distribution patterns of user-defined genes (***`r params$genes`***) across all samples in combined expression dataset. The data combination includes filtering out genes with low counts `r if ( !params$filter ) { c("(this step is skipped)") }`, transformation (`r params$transform` method, `r if ( !params$log ) { c("with no log-transformation") } else if ( params$log ) { c("followed by log2-transformation") }`), normalisation (`r params$norm`) and scaling (`r if ( tolower(params$scaling) == "gene-wise" ) { c("Z-score tansformation") } else { c("centering") }`). The pipeline is based on recommendations from *[RNAseq123](https://master.bioconductor.org/packages/release/workflows/vignettes/RNAseq123/inst/doc/limmaWorkflow.html){target="_blank"}* package.

***

<details>
<summary>Input parameters</summary>
<font size="2">

* **datasets**: `r params$datasets`
* **report_dir**: `r params$report_dir`
* **transform**: `r params$transform`
* **norm**: `r params$norm`
* **batch_rm**: `r params$batch_rm`
* **filter**: `r params$filter`
* **log**: `r params$log`
* **genes**: `r params$genes`
* **top_genes**: `r params$top_genes`
* **ensembl**: `r params$ensembl`
* **samples**: `r params$samples`
* **results_name**: `r params$results_name`
* **scaling**: `r params$scaling`
* **ref_data_dir**: `r params$ref_data_dir`
* **ensembl_version**: `r params$ensembl_version`
* **hide_code_btn**: `r params$hide_code_btn`

</font> 
</details>

```{r code_display, echo = FALSE}
##### Include or exclude the "Code" buttom allowing to "show"/"hide" code chunks from the report 
if ( params$hide_code_btn ) {
  writeLines(".btn { display: none ;", con = "combinedExprDataDistribution.css")
} else {
  writeLines(" ", con = "combinedExprDataDistribution.css")
}
```

```{r define_functions, comment=NA, message=FALSE, warning=FALSE}
### Define functions

##### Create 'not in' operator
"%!in%" <- function(x,table) match(x,table, nomatch = 0) == 0
##### Prepare object to write into a file
prepare2write <- function (x) {
  
  x2write <- cbind(rownames(x), x)
  colnames(x2write) <- c("Gene",colnames(x))
  return(x2write)
}
##### Prepare gene data matrix to write into a file
geneMatrix2write <- function (x) {
  
  x2write <- cbind(rownames(x), x)
  colnames(x2write) <- c("Gene",colnames(x))
  return(x2write)
}

##### Assign colours to different groups
getTargetsColours <- function(targets) {
  
  ##### Predefined selection of colours for groups
  targets.colours <- c("red","blue","green","darkgoldenrod","darkred","deepskyblue", "coral", "cornflowerblue", "chartreuse4", "bisque4", "chocolate3", "cadetblue3", "darkslategrey", "lightgoldenrod4", "mediumpurple4", "orangered3","indianred1","blueviolet","darkolivegreen4","darkgoldenrod4","firebrick3","deepskyblue4", "coral3", "dodgerblue1", "chartreuse3", "bisque3", "chocolate4", "cadetblue", "darkslategray4", "lightgoldenrod3", "mediumpurple3", "orangered1")
  
  f.targets <- factor(targets)
  vec.targets <- targets.colours[1:length(levels(f.targets))]
  targets.colour <- rep(0,length(f.targets))
  for(i in 1:length(f.targets))
    targets.colour[i] <- vec.targets[ f.targets[i]==levels(f.targets)]
  
  return( list(vec.targets, targets.colour) )
}

##### Assign colours to different distributions
getGenesColours <- function(genes) {
  
  ##### Predefined selection of colours for genes
  genes.colours <- rainbow(length(genes))

  f.genes <- factor(genes)
  vec.genes <- genes.colours[1:length(levels(f.genes))]
  genes.colour <- rep(0,length(f.genes))
  for(i in 1:length(f.genes)){
    genes.colour[i] <- vec.genes[ f.genes[i]==levels(f.genes)]
  }
  
  return( genes.colour )
}

##### Assign colours to different samples
getSamplesColours <- function(samples) {
  
  ##### Predefined selection of colours for genes
  samples.colours <- brewer.pal(length(samples), "Set1")

  f.samples <- factor(samples)
  vec.samples <- samples.colours[1:length(levels(f.samples))]
  samples.colour <- rep(0,length(f.samples))
  for(i in 1:length(f.samples)){
   samples.colour[i] <- vec.samples[ f.samples[i]==levels(f.samples)] 
  }
  
  return( samples.colour )
}

##### Calculate TPM from RPKM (from http://luisvalesilva.com/datasimple/rna-seq_units.html )
tpm_from_rpkm <- function(x) {
  rpkm.sum <- colSums(x)
  return(t(t(x) / (1e-06 * rpkm.sum)))
}

##### Convert density to counts
density2freq <- function(density) {

  freq = length(density)/sum(density) * density
  return(freq)
}

##### Assign colours to different datasets
getDatasetsColours <- function(datasets) {
  
  ##### Predefined selection of colours for datasets
  datasets.colours <- c("dodgerblue","firebrick","lightslategrey","darkseagreen","orange","darkcyan","bisque", "coral2", "cadetblue3","red","blue","green")
  
  f.datasets <- factor(datasets)
  vec.datasets <- datasets.colours[1:length(levels(f.datasets))]
  datasets.colour <- rep(0,length(f.datasets))
  for(i in 1:length(f.datasets))
    datasets.colour[i] <- vec.datasets[ f.datasets[i]==levels(f.datasets)]
  
  return( list(vec.datasets, datasets.colour) )
}

##### Perform PCA. This function outputs a list with dataframe and samples colouring info ready for plotting
pca <- function(data, targets, dim) {

  ##### Keep only genes with variance > 0 across all samples
  rsd <- apply(data,1,sd)
  data.subset <- data[rsd>0,]
  rsd <- rsd[rsd>0]
  
  ##### Keep top genes with the highest expression variance across samples
  rsd<-apply(data.subset,1,sd)
  
  if ( nrow(data.subset) < params$top_genes ) {
      sel<-order(rsd, decreasing=TRUE)[1:nrow(data.subset)]
  } else {
      sel<-order(rsd, decreasing=TRUE)[1:params$top_genes]
  }

  ##### Subset genes
  data.subset <- data.frame(data.subset[sel,])

  ##### Perform PCA
  data.subset_pca <- prcomp(t(data.subset), scale=FALSE)
  
  ##### Get variance importance for all principal components
  importance_pca <- summary(data.subset_pca)$importance[2,]
  importance_pca <- paste(round(100*importance_pca, 2), "%", sep="")
  names(importance_pca) <- names(summary(data.subset_pca)$importance[2,])
    
  ##### Prepare data frame
  data.subset_pca.df <- data.frame(targets$Target, targets$Dataset, data.subset_pca$x[,"PC1"], data.subset_pca$x[,"PC2"], data.subset_pca$x[,"PC3"])
  colnames(data.subset_pca.df) <- c("Target", "Dataset", "PC1", "PC2", "PC3")
  
  ##### Assigne colours to targets and datasets
  targets.colour <- getTargetsColours(targets$Target)
  datasets.colour <- getDatasetsColours(targets$Dataset)
  
  ##### Create a list with dataframe and samples colouring info
  pca.list <- list(data.subset_pca.df, importance_pca, targets.colour, datasets.colour)
  names(pca.list) <- c("pca.df", "importance_pca", "targets", "datasets")
  
  ##### Generate PCA 2-D plot
  if ( dim == 2 ) {
    pca_plot <- plot_ly(data.subset_pca.df, x = ~PC1, y = ~PC2, color = ~Target, text=paste(targets$Target, rownames(data.subset_pca.df), sep=": "), colors = targets.colour[[1]], type='scatter', mode = "markers", marker = list(size=10, opacity = 0.7), width = 800, height = 400) %>%
    layout(title = "", xaxis = list(title = paste( "PC1", " (",importance_pca["PC1"],")",sep="")), yaxis = list(title = paste( "PC2", " (",importance_pca["PC2"],")",sep="")), margin = list(l=50, r=50, b=50, t=20, pad=4), autosize = FALSE, showlegend = TRUE, legend = list(orientation = "v", y = 0.9))
    
  ##### Generate PCA 3-D plot
  } else if (dim == 3 ) {
    pca_plot <- plot_ly(data.subset_pca.df, x = ~PC1, y = ~PC2, z = ~PC3, color = ~Target, text=paste(targets$Target, rownames(data.subset_pca.df), sep=": "), colors = targets.colour[[1]], type='scatter3d', mode = "markers", marker = list(size=6, opacity = 0.7), width = 800, height = 700) %>%
    layout(title = "", scene = list(xaxis = list(title = paste( "PC1", " (",importance_pca["PC1"],")",sep="")), yaxis = list(title = paste( "PC2", " (",importance_pca["PC2"],")",sep="")), zaxis = list(title = paste( "PC3", " (",importance_pca["PC3"],")",sep=""))) , margin = list(l=50, r=50, b=50, t=10, pad=4), autosize = FALSE, showlegend = TRUE, legend = list(orientation = "v", y = 0.7))
  }
  
  ##### Generate scree plot
  data.subset_scree.df <- data.frame(paste0("PC ", c(1:length(importance_pca))), as.numeric(gsub("%", "",importance_pca)))
colnames(data.subset_scree.df) <- c("PC", "Variances")

  ##### The default order will be alphabetized unless specified as below
  data.subset_scree.df$PC <- factor(data.subset_scree.df$PC, levels = data.subset_scree.df[["PC"]])
  
  scree_plot <- plot_ly(data.subset_scree.df, x = ~PC, y = ~Variances, type = 'bar', width = 800, height = 400) %>%
    layout(title = "", xaxis = list(title = ""), margin = list(l=50, r=50, b=100, t=20, pad=4), autosize = F)
  
  return( list(pca.list, pca_plot, scree_plot) )
}

##### Generate box-plot for selected genes, highlighting samples of interest. Currently, this function works for one gene at a time.
boxPlot <- function(genes, data, target, y_title) {

  ##### Used data for user-defined genes
  data <- data[ genes, ,drop=FALSE]
  
  ##### Assigne colours to targets and datasets
  targets.colour <- getTargetsColours(target$Target)
  
  ##### Prepare data frame
  data.df <- data.frame(target$Target, colnames(data), as.numeric(data))
  colnames(data.df) <- c("Group","Sample", "Data")
  
  ##### The default order will be alphabetized unless specified as below
  data.df$Sample <- factor(data.df$Sample, levels = data.df[["Sample"]])
  p <- plot_ly(data.df, x = ~Sample, y = ~Data, color = ~Group, type = 'bar', colors = targets.colour[[1]], width = 800, height = 400) %>%
    layout(title = "", xaxis = list( tickfont = list(size = 10), title = ""), yaxis = list(title = y_title), margin = list(l=50, r=50, b=150, t=50, pad=4), autosize = F, legend = list(orientation = 'v', y = 0.5), showlegend=TRUE)
  
  return( p )
}

##### Generate scatter plots for samples (highlighting the samples and genes of interest) to illustrate the effect of data normalization and z-score transformation/centering. Currently, this function works for one gene at a time.
comparePlot <- function(genes, dataset1, dataset2, main_title, x_title, y_title, sampleName) {
  
  ##### Used data for user-defined genes
  dataset1 <- dataset1[ genes, ,drop=FALSE]
  dataset2 <- dataset2[ genes, ,drop=FALSE]
 
  ##### Make sure that samples are in the same order
  dataset2 <- dataset2[ , colnames(dataset1) ,drop=FALSE]
  
  #### Interactive genes distribution plot
  ##### Create empty data frame
  data.df <- data.frame(matrix(ncol = 4, nrow = 0))
  colnames(data.df) <- c("gene", "sample", "dataset1", "dataset2")
  
  for (i in 1:nrow(dataset1)) {
      data.df <- rbind( data.df, data.frame( gene = genes[i], sample = names(dataset1[ genes[i], ]), dataset1 = as.numeric(dataset1[ genes[i], ]), dataset2 = as.numeric(dataset2[ genes[i], ])) )
  }
  
  ##### Extract expression for selected sample in the distributions dataframe
  data.df.selected <- data.frame(matrix(ncol = 5, nrow = 0))
  colnames(data.df.selected) <- c("data", "gene", "sample", "expr", "dens")
  
  for ( i in 1:length(sampleName) ) {
    data.df.selected <- rbind(data.df.selected, data.df[sampleName[i] == data.df$sample, ])
  }
  
  ##### Assign colours to distributions
  genes.colour <- getGenesColours(unique(data.df$gene))
  
  ##### Assign colours to samples
  sample.colour <- getSamplesColours(unique(data.df.selected$sample))

  ##### Generate interactive density plot
  p <- plotly::plot_ly(data.df, x = ~dataset1, y = ~dataset2, type = 'scatter', color = ~gene, colors = genes.colour, text = data.df$sample, width = 00, height = 400) %>%
    plotly::add_markers(y = data.df.selected$dataset2, x = data.df.selected$dataset1, 
                name = data.df.selected$sample,
                text = data.df.selected$sample,
                mode = 'markers',
                marker = list(size = 8, colors = data.df.selected$sample, color = rep(sample.colour, each = nrow(data.df.selected)/length(samples)), line = list(color = "grey", width = 2)),
                showlegend = TRUE, inherit = FALSE) %>%
    
    ##### Add Loess smoothed line
    plotly::add_lines(x = data.df$dataset1, y = ~fitted(loess(data.df$dataset2 ~ data.df$dataset1)),
            line = list(color = 'grey'),
            name = "Loess Smoother", opacity = 0.5, showlegend = TRUE) %>%
    plotly::layout(title = main_title,
           xaxis = list(title = x_title),
           yaxis = list (title = y_title))
  
  return( p )
}

##### Generate density and expression distribution plots for selected genes, highlighting samples of interest. Currently, this function works for one gene at a time.
densityPlot <- function(genes, data, main_title, x_title, sampleName, distributions = NULL) {
  
  ##### Used data for user-defined genes
  data <- data[ genes, ,drop=FALSE]
  
  ##### Transformed data for html report
  ##### Create empty data frame
  data.df <- data.frame(matrix(ncol = 4, nrow = 0))
  colnames(data.df) <- c("gene", "sample", "expr", "dens")
  
  for (i in 1:nrow(data)) {
      data.df <- rbind(data.df, data.frame(gene = genes[i], sample = names(data[ genes[i], ]), expr = sort(as.numeric(data[ genes[i], ])), dens = density2freq(density(as.numeric(data[i,]), n=ncol(data))$y)))
  }
  
  ##### Generate values to generate various distributions
  if ( !is.null(distributions) && length(genes) == 1 ) {
    
    ##### Use the density values obtained from the expression values
    expr.sorted <- as.numeric(sort(data[ genes, ]))
    
    ##### Get min and max values based on the expression data
    data.x <- seq(min(expr.sorted), max(expr.sorted), length.out = ncol(data))
    
    ##### Create empty data frame
    data.df.dist <- data.frame(matrix(ncol = 4, nrow = 0))
    colnames(data.df.dist) <- c("gene", "sample", "expr", "dens")
    
    ##### Generate y-values to mirror distributions of interest
    ##### Generate y-values for normal distribution. Useful resource https://stats.idre.ucla.edu/r/modules/probabilities-and-distributions/
    if ( "normal" %in% tolower(distributions) ) {
      
      ##### Generate y-values for normal distribution
      data.y <- dnorm(data.x, mean = mean(data.x), sd = (max(data.x)-mean(data.x))/5)
      data.df.dist <- rbind(data.df.dist, data.frame(gene="Normal distribution", sample = names(sort(data[ genes, ])), expr=data.x, dens=density2freq(data.y)))
    } 
    
    if ( "binomial" %in% tolower(distributions) ) {
      
      ##### Generate x- and y-values for binomial distribution. Useful link https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Binomial.html
      #data.x <- round(seq(min(data), max(data), length.out = ncol(data)), digits = 0)
      data.x <- 1:ncol(data)
      data.y <- dbinom(data.x, ncol(data), 0.10)
      
      data.x <- rescale(data.x, to = c(min(expr.sorted), max(expr.sorted)))
      data.df.dist <- rbind(data.df.dist, data.frame(gene="Binomial distribution (p=0.25)", sample = names(sort(data[ genes, ])), expr=data.x, dens=density2freq(data.y)))
      
      data.x <- 1:ncol(data)
      data.y <- dbinom(data.x, ncol(data), 0.65)
      
      data.x <- rescale(data.x, to = c(min(expr.sorted), max(expr.sorted)))
      data.df.dist <- rbind(data.df.dist, data.frame(gene="Binomial distribution (p=0.75)", sample = names(sort(data[ genes, ])), expr=data.x, dens=density2freq(data.y)))
    }
    
    if ( "bimodal" %in% tolower(distributions) ){
      
      ##### Draw n/2 samples from a normal distributions with one median and another n/2 samples from a second normal distribution with a different median. Useful link                  https://stats.stackexchange.com/questions/355344/simulating-a-bimodal-distribution-in-the-range-of-15-in-r
      data.x1 <- seq(min(expr.sorted), median(expr.sorted), length.out = round((ncol(data)+0.5)/2, digits=0))
      data.x2 <- seq(median(expr.sorted), max(expr.sorted), length.out = trunc((ncol(data)+0.5)/2))
      
      ##### Combine both normal distributions to generate a bimodal distribution
      data.x <- c(data.x1, data.x2)
      
      ##### Generate y-values for bimodal distribution
      data.y <- c(dnorm(data.x1, mean = mean(data.x1), sd = (max(data.x1)-mean(data.x1))/3), dnorm(data.x2, mean = mean(data.x2), sd = (max(data.x2)-mean(data.x2))/3))
      
      ##### Add bimodal dist values to the distribution dataframe
      data.df.dist <- rbind(data.df.dist, data.frame(gene="Bimodal distribution", sample = names(sort(data[ genes, ])), expr=data.x, dens=density2freq(data.y)))
    }
    
    data.df <- rbind(data.df, data.df.dist)
    
    ##### Extract expression for selected sample in the distributions dataframe
    data.df.selected <- data.frame(matrix(ncol = 4, nrow = 0))
    colnames(data.df.selected) <- c("gene", "sample", "expr", "dens")
    for ( i in 1:length(sampleName) ) {
      data.df.selected <- rbind(data.df.selected, data.df[sampleName[i] == data.df$sample, ])
    }
  }
  
  ##### Get min and max values based on the expression data
  den.x <- sort(data.df$expr)
  den.y <- sort(data.df$dens)
  
  ##### Assign colours to distributions
  genes.colour <- getGenesColours(unique(data.df$gene))
  
  ##### Assign colours to samples
  sample.colour <- getSamplesColours(unique(data.df.selected$sample))

  ##### Generate interactive density plot
  p <- plotly::plot_ly(data.df, x = ~expr, y = ~dens, type = 'scatter', mode = 'lines', color = ~gene, colors = genes.colour, width = 800, height = 300) %>%
    plotly::add_markers(y = data.df.selected$dens, x = data.df.selected$expr, 
                name = data.df.selected$sample,
                text = data.df.selected$sample,
                mode = 'markers',
                marker = list(size = 8, colors = data.df.selected$sample, color = rep(sample.colour, each = nrow(data.df.selected)/length(samples)), line = list(color = "grey", width = 2)),
                showlegend = TRUE,
                inherit = FALSE) %>%
     plotly::layout(title = main_title,
           xaxis = list(title = x_title, range = c(den.x[1],den.x[length(den.x)])),
           yaxis = list (title = 'Weight', range = c(den.y[1],den.y[length(den.y)])))
  
return( p )
}

##### A wrapper to saveWidget which compensates for arguable BUG in saveWidget which requires `file` to be in current working directory (see post https://github.com/ramnathv/htmlwidgets/issues/299 )
saveWidgetFix <- function ( widget, file, ...) {
  wd<-getwd()
  on.exit(setwd(wd))
  outDir<-dirname(file)
  file<-basename(file)
  setwd(outDir);
  htmlwidgets::saveWidget(widget,file=file,...)
}
```

```{r load_libraries, warning=FALSE}
### Load libraries
suppressMessages(library(preprocessCore))
suppressMessages(library(edgeR))
suppressMessages(library(tidyverse))
suppressMessages(library(plotly))
suppressMessages(library(ComplexHeatmap))
suppressMessages(library(scales))
suppressMessages(library(truncnorm))
suppressMessages(library(RColorBrewer))
suppressMessages(library(limma))
suppressMessages(library(htmltools))
suppressMessages(library(package=paste0("EnsDb.Hsapiens.v", params$ensembl_version), character.only = TRUE))
```

```{r load_data, message=FALSE, warning=FALSE}
##### Read file with datasets information
DatasetInput=read.table(params$datasets,sep="\t", as.is=TRUE, header=TRUE, row.names=1)

if ( nrow(DatasetInput) == 1 ) {
  
  names(DatasetInput)[1:ncol(DatasetInput)-1] <- names(DatasetInput)[2:ncol(DatasetInput)]
  DatasetInput <- DatasetInput[, -c(ncol(DatasetInput))]
}

##### Extract info about target file for the first dataset
fileInfo = strsplit(DatasetInput[,"Target_file"], split='/', fixed=TRUE)
targetFile <- read.table(paste(params$report_dir, DatasetInput[1,"Target_file"], sep="/"), sep="\t", as.is=TRUE, header=TRUE)

##### Make sure that there are no duplciated samples in the target file
targetFile <- targetFile[!duplicated(targetFile[,"Sample_name"]),]
rownames(targetFile) <- targetFile[,"Sample_name"]
targetFile <- cbind(targetFile[,"Target", drop = FALSE],rownames(DatasetInput[1,]))
colnames(targetFile)[ncol(targetFile)] <- "Dataset"

##### Create a list of target file for individual datasets
targetFile.list <- vector("list", nrow(DatasetInput))
names(targetFile.list) <- rownames(DatasetInput)

##### Make syntactically valid names
rownames(targetFile) <- make.names(rownames(targetFile))
targetFile.list[[1]] <- targetFile
      
##### List datasets with only one sample available
Dataset.skip <- NULL
  
if ( nrow(DatasetInput) > 1 ) {
  for ( i in 2:nrow(DatasetInput) ) {
    
    ##### Create a temporary object to store info from the remaining target files
    targetFile.list[[i]] <- read.table(paste(params$report_dir, DatasetInput[i,"Target_file"], sep="/"), sep="\t", as.is=TRUE, header=TRUE)
    
    ##### Make sure that there are > 1 samples in each dataset. Otherwise discard them
    if ( nrow(targetFile.list[[i]]) > 2 ) {
    
      ##### Make sure that there are no duplciated samples in the target file
      targetFile.list[[i]] <- targetFile.list[[i]][!duplicated(targetFile.list[[i]][,"Sample_name"]),]
      rownames(targetFile.list[[i]]) <- targetFile.list[[i]][,"Sample_name"]
      targetFile.list[[i]] <- cbind(targetFile.list[[i]][,"Target", drop = FALSE],rownames(DatasetInput[i,]))
      colnames(targetFile.list[[i]])[ncol(targetFile.list[[i]])] <- "Dataset"
      
      ##### Deal with replicates
      if ( !is.na(match("Replicates", colnames(targetFile))) ) {
        if ( any(!is.na(targetFile[,"Replicates"])) ) {
          maxRep <- max(targetFile[!is.na(targetFile[,"Replicates"]),"Replicates"])
          targetFile.list[[i]][,"Replicates"] <- targetFile.list[[i]][,"Replicates"] + maxRep
        }
      }
      
      ##### Make syntactically valid names
      rownames(targetFile.list[[i]]) <- make.names(rownames(targetFile.list[[i]]))
      
      targetFile <- rbind(targetFile, targetFile.list[[i]])
      
    } else {
      Dataset.skip <- c( Dataset.skip, names(targetFile.list)[i] )
      DatasetInput <- DatasetInput[-i,]
    }
  }
}

##### Loop through the gene-by-sample expression matrices from different datasets and merge them into a matrix
for ( i in 1:nrow(DatasetInput) ) {
  
  ##### Create combined dataset variable if it doesn't exist yet
  if (!exists("datasets")) {
    datasets <- as.data.frame( read.table(gzfile(paste(params$report_dir, DatasetInput[ i, "Expression_matrix" ], sep="/")), header=TRUE, sep="\t", row.names=NULL) )
    
    ##### Make syntactically valid names
    colnames(datasets) <- make.names(colnames(datasets))

    ##### Make sure that the target file contains info only about samples present in the data matrix
    targetFile.list[[i]] <- targetFile.list[[i]][ rownames(targetFile.list[[i]]) %in% colnames(datasets),  ]
    
    ##### Make sure that the samples order in the data matrix is the same as in the target file 
    datasets <- cbind(datasets[,1], datasets[ , rownames(targetFile.list[[i]]), drop = FALSE ])
    
    ##### list genes present in individal files
    gene_list <- as.vector(datasets[,1])
    gene_list.missing <- NULL
    
    ##### Add data for the remaining samples   
  } else if (exists("datasets")) {
    dataset <-as.data.frame( read.table(gzfile(paste(params$report_dir, DatasetInput[ i, "Expression_matrix" ], sep="/")), header=TRUE, sep="\t", row.names=NULL) )
    
    ##### Make syntactically valid names
    colnames(dataset) <- make.names(colnames(dataset))
    
    ##### Make sure that the target file contains info only about samples present in the data matrix
    targetFile.list[[i]] <- targetFile.list[[i]][ rownames(targetFile.list[[i]]) %in% colnames(dataset),  ]
  
    ##### Make sure that the samples order in the data matrix is the same as in the target file 
    dataset <- cbind(dataset[,1], dataset[ , rownames(targetFile.list[[i]]), drop = FALSE ])
    
    ##### list genes present in individal files
    gene_list <- c( gene_list, as.vector(dataset[,1]) )
    
    ##### Identify genes that were not present across all per-sampel files and were ommited in the merged matrix
    gene_list <- unique(gene_list)
    gene_list.missing <- gene_list[ gene_list %!in% dataset[,1] ]
                                  
    ##### Merge the expression data and make sure that the genes order is the same
    datasets <- merge( datasets, dataset, by=1, all = FALSE, sort= TRUE)
    
    ##### Remove per-sample data for merged samples to free some memory
    rm(dataset)
  }
}

##### Use gene IDs as rownames
rownames(datasets) <- datasets[,1]
datasets <- datasets[, -1]

##### Make syntactically valid names
colnames(datasets) <- make.names(colnames(datasets))

##### Make sure that the target file contains info only about samples present in the data matrix
targetFile <- targetFile[ rownames(targetFile) %in% colnames(datasets),  ]

##### Make sure that the samples order in the data matrix is the same as in the target file 
datasets <- datasets[ , rownames(targetFile) ]

##### Write list of missing genes into a file
if ( length(gene_list.missing) > 0 ) {
  write.table(prepare2write(gene_list.missing), file = paste0(params$report_dir, "/", params$results_name,".missing_genes.txt"), sep="\t", quote=FALSE, row.names=TRUE, append = FALSE )
}

#### Prepare input samples of interest
if ( !is.na(params$samples) ) {
  
  samples <- make.names(unique(unlist(strsplit(params$samples, split=',', fixed=TRUE))))
  ##### Change the target file to mark the sample of interest
  targetFile$Target[ rownames(targetFile) %in% samples ] <- "Queried sample(s)"
  
} else {
  samples <- rownames(targetFile)
}

##### Create a list with datasets and accompanying data
dataset <- "combined"
datasets.list <- vector("list", 1)
names(datasets.list) <- dataset

datasets.list[[dataset]][["combined_data"]] <- datasets
datasets.list[[dataset]][["sample_annot"]] <- targetFile

##### Get user-defined genes
genes <- unique(unlist(strsplit(params$genes, split=',', fixed=TRUE)))
```

***

`r if ( !is.na(params$samples) ) { c(paste0("\nThese sample(s) were queried and will be highlighted: **", paste0(params$samples, collapse = ", "), "**\n\n")) } else { c("No specific sample(s) were queried so all will be highlighted on the plots.") }`


`r if ( !is.null(Dataset.skip) ) { c(paste0("\n**NOTE**: The following dataset(s) will be ignored in the analysis since only one sample is available: <span style=\"color:#ff0000\">", paste(Dataset.skip, collapse = ", "), "</span>!\n")) } else { c(" ") }`


`r if ( any( samples %!in% colnames(datasets) ) || any( samples %!in% rownames(targetFile) ) ) { c("\n**NOTE**: sample(s) listed below will be ignored in the analysis!\n") } else { c(" ") }`

`r if ( any( samples %!in% rownames(targetFile) ) ) { c(paste0("\nQueried sample(s): <span style=\"color:#ff0000\">", paste0(samples[ samples %!in%rownames(targetFile) ], collapse = ", "), "</span> are not present in the samples annotation file.\n\n")) }`

`r if ( any( samples %!in% colnames(datasets) ) ) { c(paste0("\nQueried sample(s) <span style=\"color:#ff0000\">", paste0(samples[ samples %!in%colnames(datasets) ], collapse = ", "), "</span> are not present in the read count data.\n\n")) }`

`r c(paste0("In total **", ncol(datasets.list[[dataset]][["combined_data"]]), "** samples were analysed."))`

***

## Library size

Bar-plot illustrating library size for each sample.

```{r library_size_plot, message = FALSE, warning=FALSE, fig.width = 12, fig.height = 9}
suppressMessages(library(plotly))
##### Generate bar-plot for library size. The colours indicate sample groups, as provided in *Target* column in the sample annotation file
data <- datasets.list[[dataset]][["combined_data"]]
target <- datasets.list[[dataset]][["sample_annot"]]

##### Assigne colours to targets and datasets
targets.colour <- getTargetsColours(target$Target)

##### Prepare data frame
data.df <- data.frame(target$Target, colnames(data), as.numeric(colSums(data)*1e-6))
colnames(data.df) <- c("Group","Sample", "Library_size")

##### The default order will be alphabetized unless specified as below
data.df$Sample <- factor(data.df$Sample, levels = data.df[["Sample"]])
p <- plot_ly(data.df, x = ~Sample, y = ~Library_size, color = ~Group, type = 'bar', colors = targets.colour[[1]], width = 800, height = 400) %>%
  layout(title = "", xaxis = list( tickfont = list(size = 10), title = ""), yaxis = list(title = "Library size (millions)"), margin = list(l=50, r=50, b=150, t=50, pad=4), autosize = F, legend = list(orientation = 'v', y = 0.5), showlegend=TRUE)

##### Print htmlwidget
p

##### Save the bar-plot as html (PLOTLY)
saveWidgetFix(p, file = paste0(params$report_dir, "/", params$results_name,".RNAseq_libSize.html"))

##### Detach plotly package. Otherwise it clashes with other graphics devices
detach("package:plotly", unload=FALSE)
```

```{r gene_annot, comment = NA, message=FALSE, warning=FALSE, eval = params$ensembl}
##### Get genes annotation and genomic locations
edb <- eval(parse(text = paste0("EnsDb.Hsapiens.v", params$ensembl_version)))
  
##### Get keytypes for gene SYMBOL
keys <- keys(edb, keytype="GENEID")
  
##### Get genes genomic coordiantes
gene_info <- ensembldb::select(edb, keys=keys, columns=c("GENEID", "GENEBIOTYPE", "GENENAME", "SEQNAME", "GENESEQSTART", "GENESEQEND"), keytype="GENEID")
names(gene_info) <- gsub("GENEID", "ENSEMBL", names(gene_info))
names(gene_info) <- gsub("GENENAME", "SYMBOL", names(gene_info))
  
##### Limit genes annotation to those genes for which sample expression measurments are available
gene_info <-  gene_info[ gene_info$ENSEMBL %in% rownames(data),  ]
  
##### Remove rows with duplicated ENSEMBL IDs
gene_info = gene_info[!duplicated(gene_info$ENSEMBL),]
rownames(gene_info) <- gene_info$ENSEMBL
  
##### Remove rows with duplicated gene symbols (Y_RNAs, SNORs, LINC0s etc)
gene_info = gene_info[!duplicated(gene_info$SYMBOL),]

##### Loop through combined datasets and annotate genes
for ( dataset in names(datasets.list) ) {
  
  ##### Convert data into a data frame to make the Ensembl ID and gene symbol matches (with merge function)
  data.df <- as.data.frame(cbind(rownames(data), data))
  colnames(data.df)[1] <- "ENSEMBL"
  
  ##### Merge genes genomic coordinates info with their annotation and expression data
  data.annot <- merge(gene_info, data.df, by = "ENSEMBL", all.x = FALSE)
  
  ##### Keep only genes fo which gene symbol is available
  data.annot <- data.annot[!(is.na(data.annot$SYMBOL) | data.annot$SYMBOL==""), ]
  rownames(data.annot) <- data.annot$SYMBOL
  
  ##### Get data matrix with gene symbols
  datasets.list[[dataset]][["combined_data"]] <- apply(data.annot[, colnames(data)], 2, as.numeric)
  rownames(datasets.list[[dataset]][["combined_data"]]) <- data.annot$SYMBOL
  datasets.list[[dataset]][["gene_annot"]] <- data.annot[, c("SYMBOL", "GENEBIOTYPE", "ENSEMBL", "SEQNAME", "GENESEQSTART", "GENESEQEND")]
}
```

***

## Transformation and filtering

The read count data is converted into **`r params$transform`** using *[edgeR](https://bioconductor.org/packages/release/bioc/html/edgeR.html){target="_blank"}* functions. `r if ( !params$filter ) { c("The option for filtering out genes with low counts is switched OFF") } else if ( params$filter ) { c("Genes with low counts were filtered out") }`. `r if ( !params$log ) { c("The data is not log-transformed") } else if ( params$log ) { c("The data is log2-transformed") }`.

```{r data_transformation_filtering, comment = NA, message=FALSE, warning=FALSE}
##### Filtering to remove low expressed genes. For differential expression and related analyses, gene expression is rarely considered at the level of raw counts since libraries sequenced at a greater depth will result in higher counts. Rather, it is common practice to transform raw counts onto a scale that accounts for such library size differences. Genes with very low counts across all libraries provide little evidence for differential expression. In the biological point of view, a gene must be expressed at some minimal level before it is likely to be translated into a protein or to be biologically important. In addition, the pronounced discretenes of these counts interferes with some of the statistical approximations that are used later in the pipeline. These genes should be filtered out prior to further analysis. Users should filter with CPM rather than filtering on the counts directly, as the latter does not account for differences in library sizes between samples. For instance for the CPM-transformed data we keep only genes that have CPM of 1

##### Transformation to CPM or TPM scale (see these blogs for details https://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/ and https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/ ).  CPM = Counts Per Million,  TPM = Transcripts Per Kilobase Million.

##### For counts data processing consider the investigated sample and internal reference cohort as one group  (regardless of the investigated patient tissie origin), and TCGA data (of any cancer type) as another group. This is to facilitate batch-effects (related with technical aspects) correction process
target_mod <- datasets.list[[dataset]][["sample_annot"]]
targets_mod.list <- unique(target_mod$Dataset)

##### Create lists with processed data each group
y <- vector("list", length(targets_mod.list))
names(y) <- targets_mod.list

##### Keep info about samples with the lowest and greates counts for defined CPM threshold
cpm.min <- round(min(as.numeric(colSums(datasets.list[[dataset]][["combined_data"]])*1e-6)), digits=0)
cpm.max <- round(max(as.numeric(colSums(datasets.list[[dataset]][["combined_data"]])*1e-6)), digits=0)


for ( subset in targets_mod.list ) {
  
  target <- target_mod[ target_mod$Dataset==subset, ]
  data <- datasets.list[[dataset]][["combined_data"]]
  data <- data[ , target_mod$Dataset==subset]

  ##### CPM transformation and filtering
  if ( params$filter && params$transform == "CPM" ) {
    
    ##### Create EdgeR DGEList object
    y[[subset]] <- edgeR::DGEList(counts=data,  group=target$Dataset)
    
    ##### Remove genes with CPM of at least 1 in less than 10% of samples
    keep <- rowSums(edgeR::cpm(y[[subset]])>1) >= ncol(data)/10
    
    ##### Keep the genes of interest too
    keep[ names(keep) %in% genes ] <- TRUE
    y[[subset]]$filtered <- y[[subset]][keep, , keep.lib.sizes=FALSE]
    
    
    ##### Transform the raw-scale to CPM. Add small offset to each observation to avoid taking log of zero and remove batch effect
    y[[subset]]$samples["norm.factors"] <- edgeR::calcNormFactors(y[[subset]], method = "none")$samples["norm.factors"]
    y[[subset]]$transformed <- edgeR::cpm(y[[subset]], normalized.lib.sizes=FALSE, log=params$log, prior.count=0.25)
    y[[subset]]$filtered.transformed <- edgeR::cpm(y[[subset]]$filtered, normalized.lib.sizes=FALSE, log=params$log, prior.count=0.25)
    
  ##### CPM transformation without filtering
  } else if ( !params$filter && params$transform == "CPM" ) {
    
    ##### Create EdgeR DGEList object
    y[[subset]] <- edgeR::DGEList(counts=data,  group=target$Dataset)
    
    ##### Transform the raw-scale to CPM. Add small offset to each observation to avoid taking log of zero and remove batch effect
    y[[subset]]$transformed <- edgeR::cpm(y[[subset]], normalized.lib.sizes=FALSE, log=params$log, prior.count=0.25)
    
  ##### TPM data transformation. We can convert RPKM to TPM in two different ways: from pre-calculated RPKM, by diving by the sum of RPKM values, or directly from the normalized counts. Here we calculate TPM starting from RPKM values computed using edgeR's rpkm function ( from http://luisvalesilva.com/datasimple/rna-seq_units.html )
  ##### TPM transformation with filtering
  } else if ( params$filter && params$transform == "TPM" ) {
    
    ##### Get genes lengths
    edb <- eval(parse(text = paste0("EnsDb.Hsapiens.v", params$ensembl_version)))
    
    gene.length <- lengthOf(edb, filter = GeneIdFilter(data.annot$ENSEMBL))
    
    ##### Check for which genes the lenght info is not available and remove them from the data
    genes.no_length <- data.annot$ENSEMBL[ data.annot$ENSEMBL %!in% names(gene.length)]
    data <- data[ data.annot$ENSEMBL %!in% genes.no_length, ]
    
    ##### Create EdgeR DGEList object
    y[[subset]] <- edgeR::DGEList(counts=data,  group=target$Dataset)
    
    ##### Convert data into RPKM
    y[[subset]]$transformed <- edgeR::rpkm(y[[subset]], gene.length = gene.length, normalized.lib.sizes=FALSE, log=FALSE)
    
    ##### Remove genes with TPM of at least 0.2 in less than 10% of samples
    keep <- rowSums(y[[subset]]$transformed>0.2) >= ncol(y[[subset]]$transformed)/10
    
    ##### Keep the genes of interest too
    keep[ names(keep) %in% genes ] <- TRUE
    y[[subset]]$filtered <- y[[subset]][keep, ]
    y[[subset]]$filtered.transformed <- y[[subset]]$transformed[keep, ]
    
    if ( params$norm == "sizeFactors" ) {
      sizeFactors <- edgeR::equalizeLibSizes(y[[subset]], dispersion=NULL, log=FALSE)
      y[[subset]]$norm <- edgeR::rpkm(sizeFactors$pseudo.counts, gene.length = gene.length, normalized.lib.sizes=FALSE, log=FALSE)
      
      ##### Keep genes with TPM of at least 0.2 in more than 10% of samples
      y[[subset]]$norm <- y[[subset]]$norm[keep, ]
    }
    
    ##### ... and then to TPM scale. Add small offset to each observation to avoid taking log of zero and remove batch effect
    if ( params$log ) {
      
      y[[subset]]$transformed <- log2(tpm_from_rpkm(y[[subset]]$transformed+0.25))
      y[[subset]]$filtered.transformed <- log2(tpm_from_rpkm(y[[subset]]$filtered.transformed+0.25))
      
      if ( params$norm == "sizeFactors" ) {
        y[[subset]]$norm <- log2(tpm_from_rpkm(y[[subset]]$norm+0.25))
      }
      
    } else {
      y[[subset]]$transformed <- tpm_from_rpkm(y[[subset]]$transformed)
      y[[subset]]$filtered.transformed <- tpm_from_rpkm(y[[subset]]$filtered.transformed)
    }
    
  ##### TPM transformation without filtering
  } else if ( !params$filter && params$transform == "TPM" ) {
    
    ##### Get genes lengths
    edb <- eval(parse(text = paste0("EnsDb.Hsapiens.v", params$ensembl_version)))
    
    gene.length <- lengthOf(edb, filter = GeneIdFilter(data.annot$ENSEMBL))
    
    ##### Check for which genes the lenght info is not available and remove them from the data
    genes.no_length <- data.annot$ENSEMBL[ data.annot$ENSEMBL %!in% names(gene.length)]
    data <- data[ data.annot$ENSEMBL %!in% genes.no_length, ]
    
    ##### Create EdgeR DGEList object
    y[[subset]] <- edgeR::DGEList(counts=data,  group=targetFile$subset)
    y[[subset]] <- edgeR::DGEList(counts=data,  group=target$Dataset)
    
    ##### Convert data into RPKM
    y[[subset]]$transformed <- edgeR::rpkm(y[[subset]], gene.length = gene.length, normalized.lib.sizes=FALSE, log=FALSE)
    
    if ( params$norm == "sizeFactors" ) {
      sizeFactors <- edgeR::equalizeLibSizes(y[[subset]], dispersion=NULL, log=FALSE)
      y[[subset]]$norm <- edgeR::rpkm(sizeFactors$pseudo.counts, gene.length = gene.length, normalized.lib.sizes=FALSE, log=FALSE)
    }
    
    ##### ... and then to TPM scale. Add small offset to each observation to avoid taking log of zero
    if ( params$log ) {
      
      y[[subset]]$transformed <- log2(tpm_from_rpkm(y[[subset]]$transformed+0.25))
      
      if ( params$norm == "sizeFactors" ) {
        y[[subset]]$norm <- log2(tpm_from_rpkm(y[[subset]]$norm+0.25))
      }
      
    } else {
      y[[subset]]$transformed <- tpm_from_rpkm(y[[subset]]$transformed)
    }
  }
}

##### Now combine DGEList objects created for each dataset
y[["comb"]]$transformed <- y[[targets_mod.list[1]]]$transformed
y[["comb"]]$samples <- y[[targets_mod.list[1]]]$samples

if ( params$filter ) {
  
  y[["comb"]]$filtered <- y[[targets_mod.list[1]]]$filtered$counts
  y[["comb"]]$filtered.transformed <- y[[targets_mod.list[1]]]$filtered.transformed
}

if ( length(targets_mod.list) > 1 ) {
  for ( i in 2:length(targets_mod.list) ) {
  
    y[["comb"]]$transformed <- merge(y[["comb"]]$transformed, y[[targets_mod.list[i]]]$transformed, by="row.names", all = FALSE, sort= FALSE)
    rownames(y[["comb"]]$transformed) <- y[["comb"]]$transformed[,"Row.names"]
    y[["comb"]]$transformed <- y[["comb"]]$transformed[,-1]
    
    if ( params$filter ) {
      y[["comb"]]$filtered <- merge(y[["comb"]]$filtered, y[[targets_mod.list[i]]]$filtered$counts, by="row.names", all = FALSE, sort= FALSE)
      rownames(y[["comb"]]$filtered) <- y[["comb"]]$filtered[,"Row.names"]
      y[["comb"]]$filtered <- y[["comb"]]$filtered[,-1]
    
      y[["comb"]]$filtered.transformed <- merge(y[["comb"]]$filtered.transformed, y[[targets_mod.list[i]]]$filtered.transformed, by="row.names", all = FALSE, sort= FALSE)
      rownames(y[["comb"]]$filtered.transformed) <- y[["comb"]]$filtered.transformed[,"Row.names"]
      y[["comb"]]$filtered.transformed <- y[["comb"]]$filtered.transformed[,-1]
    }
    
    y[["comb"]]$samples <- rbind(y[["comb"]]$samples, y[[targets_mod.list[i]]]$samples)
  }
}
```

`r if ( params$transform == "CPM" ) { paste0("The CPM of 1 (cut-off for removing low expressed genes) corresponds to ", cpm.min, " reads in sample with the lowest sequencing depth, and ", cpm.max, " reads in sample with the greatest sequencing depth. The plot below presents the relation between read counts and the corresponding ", params$transform, " values in a sample with the lowest sequencing depth. The red vertical line indicates the threshold for filtering genes with low counts.") } else { paste0("The plot below presents the relation between read counts and the corresponding ", params$transform, " values in the patient data. The red vertical line indicates the threshold for filtering genes with low counts.") }`

```{r filtering_plot, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6, fig.show="hide", eval = params$filter}
##### Plot read counts against transformed data
suppressMessages(library(plotly))
  
##### Organise the data into data frame
data.df <- as.data.frame(cbind( y[["comb"]]$transformed[,order(colSums(datasets.list[[dataset]][["combined_data"]]))[1]]+1, datasets.list[[dataset]][["combined_data"]][,order(colSums(datasets.list[[dataset]][["combined_data"]]))[1]]))
names(data.df) <- c("Transformed", "Counts")
  
##### Keep only genes with read counts below the 99th percentile
data.df <- data.df[ data.df$Counts < quantile(data.df$Counts, 0.99), ]
  
##### Keep only every 25th genes to reduce the size of the plot
data.df <- data.df[ seq(1,nrow(data.df), by=25), ]

##### Generate plot for filtered data
p <- plot_ly( data.df, x = ~Transformed, y = ~Counts, width = 800, height = 300, color = I('black'), marker = list(size = 5), type="scatter", mode = "markers", name = paste0(params$transform, " vs Counts") ) %>% 
    add_trace(x = c(1, 1), y= c(0, max(data.df$Counts)), mode = "lines", color = I("red"), name = "Filtering threshold") %>%
    
    layout(title = "", xaxis = list(title = paste0(params$transform, "s")), yaxis = list(title = "Counts"), showlegend=TRUE)

##### Print htmlwidget
p

##### Save interactive plot as html file
saveWidgetFix(p, file = paste0(params$report_dir, "/", params$results_name,".counts_vs_transformed.html"))

##### Detach plotly package. Otherwise it clashes with other graphics devices
detach("package:plotly", unload=FALSE)
```

Plot(s) below present `r params$transform` data distribution `r if ( params$filter ) { c(" before and after filtering genes with low counts.") } else { cat(".")}`
 
```{r data_transformation_plot, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6}
##### Collect the most extreme density values for set the x-axis and y-axis boundaries
den.x <- density(y[["comb"]]$transformed[,1])$x
den.y <- density(y[["comb"]]$transformed[,1])$y
  
for (i in 2:ncol(y[["comb"]]$transformed)) {
    
  den <- density(y[["comb"]]$transformed[,i])
  den.x <- sort(c(den.x, den$x))
  den.y <- sort(c(den.y, den$y))
}
  
if ( params$filter ) {

  par(mfrow=c(1,2))
  
  ##### Before filtering
  plot(density(y[["comb"]]$transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed data (unfiltered)", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y[["comb"]]$transformed)){
    den <- density(y[["comb"]]$transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  
  ##### After filtering
  plot(density(y[["comb"]]$filtered.transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed and filtered data", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y[["comb"]]$filtered.transformed)){
    den <- density(y[["comb"]]$filtered.transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  
  ##### Save the plot as pdf file
  pdf(paste0(params$report_dir, "/", params$results_name,".filtering.pdf"), width=8, height=5, pointsize = 8)
  par(mfrow=c(1,2))
  
  ##### Before filtering
  plot(density(y[["comb"]]$transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed data (unfiltered)", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y[["comb"]]$transformed)){
    den <- density(y[["comb"]]$transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  
  ##### After filtering
  plot(density(y[["comb"]]$filtered.transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed and filtered data", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y[["comb"]]$filtered.transformed)){
    den <- density(y[["comb"]]$filtered.transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  invisible(dev.off())
  
} else {
  
  ##### Without filtering
  plot(density(y[["comb"]]$transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed data (unfiltered)", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y[["comb"]]$transformed)){
    den <- density(y[["comb"]]$transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  
  ##### Save the plot as pdf file
  pdf(paste0(params$report_dir, "/", params$results_name,".filtering.pdf"), width=8, height=5, pointsize = 8)
  ##### Without filtering
  plot(density(y[["comb"]]$transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed data (unfiltered)", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y[["comb"]]$transformed)){
    den <- density(y[["comb"]]$transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  invisible(dev.off())
}
```

***

## Normalisation

`r if ( tolower(params$norm) == "none" ) { c("No normalisation is performed") } else { c(paste0("During the sample preparation or sequencing process, external factors that are not of biological interest can affect the expression of individual samples. For example, samples processed in the first batch of an experiment can have higher expression overall when compared to samples processed in a second batch. It is assumed that all samples should have a similar range and distribution of expression values. Normalisation for sample-specific effects is required to ensure that the expression distributions of each sample are similar across the entire experiment. Normalisation is performed using ", params$norm, " method")) }`. 

`r if ( tolower(params$norm) != "none" ) { c(paste0("Box-plots below present ", params$transform, " data for individual samples, coloured by sample groups, before and after ", params$norm, " normalisation.")) }`

```{r data_normalisation, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 16}
##### TMM normalsation. Trimmed mean of M-values (https://www.ncbi.nlm.nih.gov/pubmed/20196867) (TMM) is performed using the calcNormFactors function in edgeR. The normalisation factors calculated here are used as a scaling factor for the library sizes. TMM is the recommended for most RNA-Seq data where the majority (more than half) of the genes are believed not differentially expressed between any pair of the samples. It adjusts for RNA composition effect, calculates scaling factors for the library sizes with calcNormFactors function using trimmed mean of M-values (TMM) between each pair of samples. Note, that the raw read counts are used to calculate the normalisation factors

#### For each dataset...
for ( subset in targets_mod.list ) {
  if ( params$transform == "CPM" ) {
    
    ##### Calculate normalization factors and  transformations from the raw-scale to CPM and normalisation using user-defined method
    if ( params$filter ) {
      
      y[[subset]]$noNorm <- y[[subset]]$filtered.transformed
      y[[subset]]$filtered$samples["norm.factors"] <- edgeR::calcNormFactors(y[[subset]]$filtered, method = params$norm)$samples["norm.factors"]
      y[[subset]]$norm <- edgeR::cpm(y[[subset]]$filtered, normalized.lib.sizes=TRUE, log=params$log, prior.count=0.25)
    
    } else {
      
      y[[subset]]$noNorm <- y[[subset]]$transformed
      y[[subset]]$samples["norm.factors"] <- edgeR::calcNormFactors(y, method = params$norm)$samples["norm.factors"]
      y[[subset]]$norm <- edgeR::cpm(y[[subset]], normalized.lib.sizes=TRUE, log=params$log, prior.count=0.25)
    }
    
  ##### Quantile normalsation (from https://www.biostars.org/p/296992/ )
  } else if ( params$transform == "TPM" ) {
    
    ##### Normalisation using quantile method
    if ( params$filter ) {
      
      y[[subset]]$noNorm <- y[[subset]]$filtered.transformed
      y[[subset]]$filtered.transformed <- data.matrix(y[[subset]]$filtered.transformed) 
      
      if ( params$norm != "sizeFactors" ) {
        if ( tolower(params$norm) != "none" ) {
          
          y[[subset]]$norm  <- normalize.quantiles(y[[subset]]$filtered.transformed, copy = TRUE)
          colnames(y[[subset]]$norm) <- colnames(y[[subset]]$filtered.transformed)
          rownames(y[[subset]]$norm) <- rownames(y[[subset]]$filtered.transformed)
          
        } else {
          y[[subset]]$norm  <- y[[subset]]$filtered.transformed
        }
      }
    
    } else {
      
      y[[subset]]$noNorm <- y[[subset]]$transformed
      y[[subset]]$transformed <- data.matrix(y[[subset]]$transformed)
      
      if ( params$norm != "sizeFactors" ) {
        if ( tolower(params$norm) != "none" ) {
          
          y[[subset]]$norm  <- normalize.quantiles(y[[subset]]$transformed, copy = TRUE)
          colnames(y[[subset]]$norm) <- colnames(y[[subset]]$transformed)
          rownames(y[[subset]]$norm) <- rownames(y[[subset]]$transformed)
          
        } else {
          y[[subset]]$norm  <- y[[subset]]$transformed
        }
      }
    }
  }
}

##### Now combine DGEList objects created for each dataset
y[["comb"]]$noNorm <- y[[targets_mod.list[1]]]$noNorm
y[["comb"]]$norm <- y[[targets_mod.list[1]]]$norm

if ( length(targets_mod.list) > 1 ) {
  for ( i in 2:length(targets_mod.list) ) {
  
    y[["comb"]]$noNorm <- merge(y[["comb"]]$noNorm, y[[targets_mod.list[i]]]$noNorm, by="row.names", all = FALSE, sort= TRUE)
    rownames(y[["comb"]]$noNorm) <- y[["comb"]]$noNorm[,"Row.names"]
    y[["comb"]]$noNorm <- y[["comb"]]$noNorm[,-1]
    
    y[["comb"]]$norm <- merge(y[["comb"]]$norm, y[[targets_mod.list[i]]]$norm, by="row.names", all = FALSE, sort= TRUE)
    rownames(y[["comb"]]$norm) <- y[["comb"]]$norm[,"Row.names"]
    y[["comb"]]$norm <- y[["comb"]]$norm[,-1]
  }
}

datasets.list[[dataset]][["combined_data_processed"]] <- y[["comb"]]$norm

##### Set height scaling factor for plots containing normalised data plots
if ( tolower(params$norm) != "none" ) {
  norm.height = 2
} else {
  norm.height = 1
}
```

```{r data_normalisation_plots, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6*norm.height}
##### Plot expression distribution of samples for unnormalised and normalised data
par(mfrow=c(2,1), mar=c(2, 5, 3, 2))
    
##### Unnormalised data
boxplot(y[["comb"]]$noNorm, col=targets.colour[[2]], main="", pch=".", las=2, xaxt = "n")
  title(main="Unnormalised data", ylab=params$transform)
legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], horiz=TRUE, bg = "transparent", box.col="transparent", cex=0.7)
    
##### Normalised data
if ( tolower(params$norm) != "none" ) {
      
  boxplot(y[["comb"]]$norm, col=targets.colour[[2]], main="", pch=".", las=2, xaxt = "n")
  title(main=paste0("Normalised data (", params$norm, ")"), ylab=params$transform, xlab = "")
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], horiz=TRUE, bg = "transparent", box.col="transparent", cex=0.7)
}
    
##### Save the plot as pdf file
pdf(paste0(params$report_dir, "/", params$results_name,".normalisation.pdf"), width=8, height=14, pointsize = 6)
par(mfrow=c(norm.height,1), mar=c(max(nchar(colnames(y[["comb"]]$noNorm)))/2, 5, 3, 2))
    
##### Unnormalised data
boxplot(y[["comb"]]$noNorm, col=targets.colour[[2]], main="", pch=".", las=2, xaxt = "n")
title(main="Unnormalised data", ylab=params$transform)
    legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], horiz=TRUE, bg = "transparent", box.col="transparent")
      
##### Normalised data
if ( tolower(params$norm) != "none" ) {
      
  boxplot(y[["comb"]]$norm, col=targets.colour[[2]], main="", pch=".", las=2, xaxt = "n")
  title(main=paste0("Normalised data (", params$norm, ")"), ylab=params$transform)
    legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], horiz=TRUE, bg = "transparent",box.col="transparent")
}
invisible(dev.off())
```


```{r library_size_norm_plot, comment = NA, message=FALSE, warning=FALSE, echo = TRUE, fig.width = 8, fig.height = 3, results="asis"}
suppressMessages(library(plotly))

lib_size_plot <- list()

##### Generate bar-plot for library size again if sizeFactors normalisation was used to see if it works
if ( params$norm == "sizeFactors" ) {

  ##### Prepare data frame
  data.df <- data.frame(colnames(y[["comb"]]$norm), as.numeric(colSums(y[["comb"]]$norm)*1e-6))
  colnames(data.df) <- c("Sample", "Library_size")
    
  ##### The default order will be alphabetized unless specified as below
  data.df$Sample <- factor(data.df$Sample, levels = data.df[["Sample"]])
  lib_size_plot[[1]] <- plot_ly(data.df, x = ~Sample, y = ~Library_size, type = 'bar', width = 800, height = 400) %>%
    layout(title = "", xaxis = list( tickfont = list(size = 10), title = ""), yaxis = list(title = "Library size (millions)"), margin = list(l=50, r=50, b=150, t=50, pad=4), autosize = F, showlegend=FALSE)
}

if ( length(lib_size_plot) == 1 ) {
  cat("\n<details>\n")
  cat("\n<summary>Normalised library size plot</summary>\n")
  cat("<font size=\"2\">\n")
  cat(renderTags(lib_size_plot[[1]])$html)
  
  cat("\n</font>\n")
  cat("\n</details>\n")
  
  ##### Save the bar-plot as html (PLOTLY)
  saveWidgetFix(p, file = paste0(params$report_dir, "/", paste0(params$results_name, ".library_size_norm.html")), selfcontained = TRUE)
}
```

```{r batch_effect_correction, comment = NA, message=FALSE, warning=FALSE}
##### The strategy for correcting data for batch effects is to consider the investigated sample and internal reference cohort as one group (batch) (regardless of the investigated patient tissiu origin), and TCGA data (of any cancer type) as another batch. The objective is to remove as much as possible data variation due to technical factors.
batches <- as.character(datasets.list[[dataset]][["sample_annot"]]$Dataset)
batch_rm_status <- FALSE

##### Perform batch-effect correctrion using limma
if ( length(unique(batches)) > 1 ) {
  if ( params$batch_rm ) {
    datasets.list[[dataset]][["batch_effect_corrected"]] <- limma::removeBatchEffect(datasets.list[[dataset]][["combined_data_processed"]], batch = batches)
    
    batch_rm_status <- TRUE
  } else {
    datasets.list[[dataset]][["batch_effect_corrected"]] <- datasets.list[[dataset]][["combined_data_processed"]]
  }
} else {
  datasets.list[[dataset]][["batch_effect_corrected"]] <- datasets.list[[dataset]][["combined_data_processed"]]
}

##### Write combined data into a file
write.table(prepare2write(datasets.list[[dataset]][["batch_effect_corrected"]]), file = paste0(params$report_dir, "/", paste0(params$results_name, ".combined.txt")), sep="\t", quote=FALSE, row.names=FALSE, append = FALSE )

##### Write list genes into a file
write.table(prepare2write(rownames(datasets.list[[dataset]][["batch_effect_corrected"]])), file = paste0(params$report_dir, "/", params$results_name,".combined_genes.txt"), sep="\t", quote=FALSE, col.names=FALSE, row.names=FALSE, append = FALSE )
```

`r if ( batch_rm_status ) { c("***") }`

`r if ( batch_rm_status ) { c("## Batch-effects correction") }`

`r if ( batch_rm_status ) { c("Scatter-plots of the first 2 principal components (PCs) constituting the primary source of variation in the data before and after batch effects correction. Each point represents the orientation of a sample in the transcriptional space projected on the PCA, with different colours representing the biological group of the sample.") }`

```{r pca_batch_effect, comment = NA, message=FALSE, warning=FALSE, eval=batch_rm_status}
suppressMessages(library(plotly))

##### Perform principal component analysis (PCA) using combined-only data and batch-effect corrected data
##### Loop through combined datasets and perform PCA
target <- datasets.list[[dataset]][["sample_annot"]]
  
datasets.list[[dataset]][["pca_combined_data_processed"]] <- pca(data=datasets.list[[dataset]][["combined_data_processed"]], targets=target, dim=2)
datasets.list[[dataset]][["pca_batch_effect_corrected"]] <- pca(data=datasets.list[[dataset]][["batch_effect_corrected"]], targets=target, dim=2)

#### Before batch-effects correction
datasets.list[[dataset]][["pca_combined_data_processed"]][[2]]

#### After batch-effects correction
datasets.list[[dataset]][["pca_batch_effect_corrected"]][[2]]

##### Detach plotly package. Otherwise it clashes with other graphics devices
detach("package:plotly", unload=FALSE)
```

***

## `r if ( tolower(params$scaling) == "gene-wise" ) { c("Z-score transformation") } else { c("Centering") }`

`r if ( tolower(params$scaling) == "gene-wise" ) { c("This step aims to put data from different sources onto the same scale. Z-scores, or standard scores, indicate how many standard deviations an observation is above or below the mean. The z-score reflects a standard normal deviate - the variation of across the standard normal distribution, which is a normal distribution with mean equal to zero and standard deviation equal to one.") } else { c("This step aims to put data from different sources onto the same scale. The centering is done by subtracting the mean expression of all genes in the corresponding sample from the expresion of queried gene in that sample.") }`

Box-plot below presents `r if ( tolower(params$scaling) == "gene-wise" ) { c("z-score transformed") } else { c("centered") }` data (`r if ( tolower(params$scaling) == "gene-wise" ) { c("gene-wise") } else { c("sample-wise") }`) for individual samples, coloured according to corresponding groups.

```{r z_transformation, comment = NA, message=FALSE, warning=FALSE}
##### Perform Z-score transformation/centering
if (tolower(params$scaling) == "gene-wise"){
  
  z_scaling <- "gene-wise"
  y[["comb"]]$z <- t(scale(t(datasets.list[[dataset]][["batch_effect_corrected"]])))
} else {
  z_scaling <- "sample-wise"
  y[["comb"]]$z <- scale(datasets.list[[dataset]][["batch_effect_corrected"]], scale = FALSE)
}

##### Define axis title for scaled data
if ( tolower(params$scaling) == "gene-wise" ) {
  scaled_title <- "z-score"
} else { 
  scaled_title <-  paste0("centered ", params$transform)
}

##### Write combined and re-scaled data into a file
write.table(prepare2write(y[["comb"]]$z), file = paste0(params$report_dir, "/", paste0(params$results_name, ".combined.z.txt")), sep="\t", quote=FALSE, row.names=FALSE, append = FALSE )

##### Write list genes into a file
write.table(prepare2write(rownames(y[["comb"]]$z)), file = paste0(params$report_dir, "/", params$results_name,".combined.z_genes.txt"), sep="\t", quote=FALSE, col.names=FALSE, row.names=FALSE, append = FALSE )
```

```{r data_z_score_plot, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6}
##### Plot expression distribution of samples for Z-score data
par(mfrow=c(1,1), mar=c(2, 5, 3, 2))

boxplot(y[["comb"]]$z, col=targets.colour[[2]], main="", pch=".", las=2, xaxt = "n")
  title(main=paste0(scaled_title, " data"), ylab=scaled_title)
legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], horiz=TRUE, bg = "transparent", box.col="transparent", cex=0.8)
    
##### Save the plot as pdf file
pdf(paste0(params$report_dir, "/", paste0(params$results_name, ".", scaled_title, ".pdf")), width=8, height=6, pointsize = 6)
par(mfrow=c(1,1), mar=c(2, 5, 3, 2))
    
boxplot(y[["comb"]]$z, col=targets.colour[[2]], main="", pch=".", las=2, xaxt = "n")
title(main=paste0(scaled_title, " data"), ylab=scaled_title)
    legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], horiz=TRUE, bg = "transparent", box.col="transparent")
invisible(dev.off())
```

***

## Exploratory data analysis {.tabset .tabset-fade}

### PCA {.tabset .tabset-fade}

Principal component analysis (PCA) transforms the data into a coordinate system and presents them in an orthogonal projection. This reduces the dimensionality of the data and facilitates exploration of their global structure, as well as the key *components* of variation of the data. The colours indicate sample groups. **`r params$top_genes` genes** with the highest expression variance across all samples were use for PCA.

#### 2D plot

Scatter-plot of the first 2 principal components (PCs) constituting the primary source of variation in `r if ( tolower(params$scaling) == "gene-wise" ) { c("z-score transformed") } else { c("centered") }` data. Each point represents the orientation of a sample in the transcriptional space projected on the PCA, with different colours representing the biological group of the sample.

`r if ( tolower(params$norm) != "none") { paste0("**Normalised ", params$transform, " (", params$norm, ")**") } else { c(" ") }`

```{r pca_2D_normalised, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6, eval = tolower(params$norm) != "none"}
suppressMessages(library(plotly))

##### Perform principal component analysis (PCA) using combined-only data
##### Loop through combined datasets and perform PCA
target <- datasets.list[[dataset]][["sample_annot"]]
  
pca(data=datasets.list[[dataset]][["batch_effect_corrected"]], targets=target, dim=2)[[2]]

##### Detach plotly package. Otherwise it clashes with other graphics devices
detach("package:plotly", unload=FALSE)
```

`r c(paste0("**", scaled_title, "**"))`

```{r pca_2D_scaled, comment = NA, message=FALSE, warning=FALSE}
suppressMessages(library(plotly))

##### Perform principal component analysis (PCA) using combined-only data
##### Loop through combined datasets and perform PCA
target <- datasets.list[[dataset]][["sample_annot"]]
  
pca(data=y[["comb"]]$z, targets=target, dim=2)[[2]]

##### Detach plotly package. Otherwise it clashes with other graphics devices
detach("package:plotly", unload=FALSE)
```

***

#### 3D plot

Scatter-plot of the first 3 principal components (PCs) constituting the primary source of variation in `r if ( tolower(params$scaling) == "gene-wise" ) { c("z-score transformed") } else { c("centered") }` data. Each point represents the orientation of a sample in the transcriptional space projected on the PCA, with different colours representing the biological group of the sample.

`r if ( tolower(params$norm) != "none") { paste0("**Normalised ", params$transform, " (", params$norm, ")**") } else { c(" ") }`

```{r pca_3D_normalised, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6, eval = tolower(params$norm) != "none"}
suppressMessages(library(plotly))

##### Perform principal component analysis (PCA) using combined-only data
##### Loop through combined datasets and perform PCA
target <- datasets.list[[dataset]][["sample_annot"]]
  
pca(data=datasets.list[[dataset]][["batch_effect_corrected"]], targets=target, dim=3)[[2]]

##### Detach plotly package. Otherwise it clashes with other graphics devices
detach("package:plotly", unload=FALSE)
```


`r c(paste0("**", scaled_title, "**"))`

```{r pca_3D_scaled, comment = NA, message=FALSE, warning=FALSE}
suppressMessages(library(plotly))

##### Perform principal component analysis (PCA) using combined-only data
##### Loop through combined datasets and perform PCA
target <- datasets.list[[dataset]][["sample_annot"]]
  
pca(data=y[["comb"]]$z, targets=target, dim=3)[[2]]

##### Detach plotly package. Otherwise it clashes with other graphics devices
detach("package:plotly", unload=FALSE)
```

### Heatmap

Heatmap presenting **`r params$top_genes` genes** (*y-axis*) with the highest expression variance across all samples (*x-axis*).

`r if ( tolower(params$norm) != "none") { paste0("**Normalised ", params$transform, " (", params$norm, ")**") } else { c(" ") }`

```{r heatmap, warning = FALSE, echo = TRUE, message = FALSE, results = 'hide', fig.width = 12, fig.height = 10}
##### Keep top genes with the highest expression variance across samples
data <- datasets.list[[dataset]][["batch_effect_corrected"]]
rsd<-apply(data,1,sd)
data <- data[rsd>0,]

if ( nrow(data) < params$top_genes ) {

    sel<-order(rsd, decreasing=TRUE)[1:nrow(data)]
} else {
    sel<-order(rsd, decreasing=TRUE)[1:params$top_genes]
}

##### Subset genes
data.h <- data.frame(data[sel,])

##### Prepare heatmap annotation (samples)
Target.col  <- targets.colour[[1]]
names(Target.col) <- sort(unique(targetFile$Target))

ha = HeatmapAnnotation(df = targetFile[, "Target", drop = FALSE], col = list(Target = Target.col ) )


##### Cluster genes
hc <- hclust(as.dist(1-cor(data.h, method="pearson")), method="ward.D2")

##### Cluster samples
hr <- hclust(as.dist(dist(data.h, method="euclidean")), method="ward.D2")

##### Generate heatmap (complexHeatmap)
if ( length(unique(targetFile$Target)) > 1 ) {
  row_split <- length(unique(targetFile$Target))
  column_split <- length(unique(targetFile$Target))
} else {
  row_split <- NULL
  column_split <- NULL
}

Heatmap(data.h, name = "expr", top_annotation = ha, cluster_rows = hr, cluster_columns = hc, row_split = row_split, column_split = column_split)
  
pdf(paste0(params$report_dir, "/", paste0(params$results_name, ".heatmap.pdf")), width = 8, height = 8)
Heatmap(data.h, name = "expr", top_annotation = ha, cluster_rows = hr, cluster_columns = hc, row_split = row_split, column_split = column_split, use_raster = FALSE)
dev.off()
```

```{r heatmap_interactive, warning = FALSE, echo = TRUE, message = FALSE, results = 'hide', fig.width = 12, fig.height = 10}
suppressMessages(library(heatmaply))

##### Generate heatmap (PLOTLY)
col_side_colors <- as.data.frame(targetFile[, "Target"])
colnames(col_side_colors) <- "Target"

col_side_palette <- targets.colour[[2]]
names(col_side_palette) <- col_side_colors$Target

p <- heatmaply(data.frame(data.h), Rowv = hr, Colv = rev(hc), k_col=1, k_row=1, colors = colorRampPalette(c("darkblue","darkblue","darkslateblue","darkslateblue","white","firebrick3","firebrick3","firebrick4","firebrick4"))(100), col_side_colors = col_side_colors, col_side_palette = col_side_palette, scale="row", trace="none", hide_colorbar = TRUE, fontsize_row = 8, fontsize_col = 8) %>%
layout(autosize = TRUE, width = 800, margin = list(l=150, r=50, b=150, t=50, pad=4), showlegend = FALSE)

##### Save the heatmap as html (PLOTLY)
saveWidgetFix(p, file = paste0(params$report_dir, "/", paste0(params$results_name, ".heatmap.html")), selfcontained = TRUE)
```

`r c(paste0("**", scaled_title, "**"))`

```{r heatmap_scaled, warning = FALSE, echo = TRUE, message = FALSE, results = 'hide', fig.width = 12, fig.height = 10}
##### Keep top genes with the highest expression variance across samples
data <- y[["comb"]]$z
rsd<-apply(data,1,sd)
data <- data[rsd>0,]

if ( nrow(data) < params$top_genes ) {

    sel<-order(rsd, decreasing=TRUE)[1:nrow(data)]
} else {
    sel<-order(rsd, decreasing=TRUE)[1:params$top_genes]
}

##### Subset genes
data.h <- data.frame(data[sel,])


##### Cluster genes
hc <- hclust(as.dist(1-cor(data.h, method="pearson")), method="ward.D2")

##### Cluster samples
hr <- hclust(as.dist(dist(data.h, method="euclidean")), method="ward.D2")

##### Generate heatmap (complexHeatmap)
if ( length(unique(targetFile$Target)) > 1 ) {
  row_split <- length(unique(targetFile$Target))
  column_split <- length(unique(targetFile$Target))
} else {
  row_split <- NULL
  column_split <- NULL
}

Heatmap(data.h, name = "expr", top_annotation = ha, cluster_rows = hr, cluster_columns = hc, row_split = row_split, column_split = column_split)
  
pdf(paste0(params$report_dir, "/", paste0(params$results_name, ".heatmap_scaled.pdf")), width = 8, height = 8)
Heatmap(data.h, name = "expr", top_annotation = ha, cluster_rows = hr, cluster_columns = hc, row_split = row_split, column_split = column_split, use_raster = FALSE)
dev.off()
```

```{r heatmap_scaled_interactive, warning = FALSE, echo = TRUE, message = FALSE, results = 'hide', fig.width = 12, fig.height = 10}
##### Generate heatmap (PLOTLY)
p <- heatmaply(data.frame(data.h), Rowv = hr, Colv = rev(hc), k_col=1, k_row=1, colors = colorRampPalette(c("darkblue","darkblue","darkslateblue","darkslateblue","white","firebrick3","firebrick3","firebrick4","firebrick4"))(100), col_side_colors = col_side_colors, col_side_palette = col_side_palette, scale="row", trace="none", hide_colorbar = TRUE, fontsize_row = 8, fontsize_col = 8) %>%
layout(autosize = TRUE, width = 800, margin = list(l=150, r=50, b=150, t=50, pad=4), showlegend = FALSE)

##### Save the heatmap as html (PLOTLY)
saveWidgetFix(p, file = paste0(params$report_dir, "/", paste0(params$results_name, ".heatmap_scaled.html")), selfcontained = TRUE)

detach("package:heatmaply", unload=FALSE)
```

***

## Selected genes expression {.tabset}

```{r data_subset, comment = NA, message=FALSE, warning=FALSE}
##### Subset data
y.sub <- y[["comb"]]
datasets.list[[dataset]][["combined_data_sub"]] <- as.data.frame(datasets.list[[dataset]][["combined_data"]])
datasets.list[[dataset]][["combined_data_sub"]] <- datasets.list[[dataset]][["combined_data_sub"]][ rownames(datasets.list[[dataset]][["combined_data_sub"]]) %in% rownames(datasets.list[[dataset]][["combined_data_processed"]]), ]

##### Identify user-defined genes that were not present in the expression matrix
if ( params$filter ) {
    
  genes.missing <- genes[ genes %!in% rownames(y[["comb"]]$filtered.transformed) ]
  genes <- genes[ genes %in% rownames(y[["comb"]]$filtered.transformed)  ]
    
  keep <- rownames(y[["comb"]]$filtered.transformed) %in% genes
  y.sub$filtered.transformed <- y[["comb"]]$filtered.transformed[keep, , drop=FALSE]
    
} else {
    
  genes.missing <- genes[ genes %!in% rownames(y[["comb"]]$transformed) ]
  genes <- genes[ genes %in% rownames(y[["comb"]]$transformed)  ]
    
  keep <- rownames(y[["comb"]]$transformed) %in% genes
  y.sub$transformed <- y.sub$transformed[keep, , drop=FALSE]
}

keep <- rownames(y.sub$noNorm) %in% genes
y.sub$noNorm <- y.sub$noNorm[keep, , drop=FALSE]
y.sub$z <- y.sub$z[keep, , drop=FALSE]
  
if ( tolower(params$norm) != "none" ) {
  y.sub$norm <- y.sub$norm[keep, , drop=FALSE]
}

##### Write list of genes into a file
if ( length(genes) > 0 ) {
    write.table(prepare2write(genes), file = paste0(params$report_dir, "/", paste0(params$results_name, ".genes.txt")), sep="\t", quote=FALSE, row.names=TRUE, append = FALSE )
  
  runChunk <- TRUE
} else {
  runChunk <- FALSE
}

##### Write list of missing genes into a file
if ( exists("genes.missing") && length(genes.missing) > 0 ) {
  write.table(prepare2write(genes.missing), file = paste0(params$report_dir, "/", paste0(params$results_name, ".genes.missing.txt")), sep="\t", quote=FALSE, row.names=TRUE, append = FALSE )
}
```

```{r prep_data_for_presenting, comment = NA, message=FALSE, warning=FALSE, eval = runChunk}
if ( params$filter ) {
  transformed.data <- y[["comb"]]$filtered.transformed
} else {
  transformed.data <- y[["comb"]]$transformed
}

##### Check if queried samples are present in the data matrix and target file. If no, then ignore them
if ( !any( samples %in% rownames(targetFile) ) ) { 
  samples <- rownames(targetFile)
} else if ( any( samples %!in% rownames(targetFile) ) ) { 
  samples <- samples[ samples %in% rownames(targetFile) ]
} else if ( any( samples %!in% colnames(transformed.data) ) ) { 
  samples <- samples[ samples %in% colnames(transformed.data) ]
}
```

### Plots {.tabset .tabset-fade}

`r if ( tolower(params$norm) != "none" ) { c(paste0("Bar-plots illustrating counts data, ", params$transform, ", normalised ", params$transform, " (", params$norm, ") and ", if ( tolower(params$scaling) == "gene-wise" ) { c("z-score transformed") } else { c("centered") }, " (", z_scaling, ") ")) } else { c(paste0("Bar-plots illustrating counts data, ", params$transform, " and ", if ( tolower(params$scaling) == "gene-wise" ) { c("z-score transformed") } else { c("centered") }, " (", z_scaling, ") ")) }` values for each sample for selected gene(s).

```{r data_barplot_counts, message = FALSE, warning=FALSE, fig.width = 12, fig.height = 9, eval = runChunk, results="asis"}
##### Generate bar-plot the each type of data
suppressMessages(library(plotly))

##### Create a list for htmlwidgets
output_counts <- list()
output_transform <- list()
output_norm <- list()
output_batch <- list()
output_z <- list()

##### For each gene generate corresponding set of plots
for ( i in 1:length(genes) ) {
  
  ##### Counts data
  output_counts[[i]] <- boxPlot(genes=genes[i], data=datasets.list[[dataset]][["combined_data_sub"]], target=target, y_title="Counts" )
  
  ##### Transformed data
  output_transform[[i]] <- boxPlot(genes=genes[i], data=transformed.data, target=target, y_title=params$transform)
    
  ##### Normalised data 
  if ( tolower(params$norm) != "none" ) {

    output_norm[[i]] <- boxPlot(genes=genes[i], data=y.sub$norm, target=target, y_title=paste0("Normalised ", params$transform, " (", params$norm, ")")) 
  }
  
  ##### Check the effect of data batch-effect correction
  if ( any(runChunk && batch_rm_status) ) {
    output_batch[[i]] <- boxPlot(genes=genes[i], data=datasets.list[[dataset]][["batch_effect_corrected"]], target=target, y_title="Batch-effects corrected") 
  }
    
  ##### Z-transformed data
  output_z[[i]] <- boxPlot(genes=genes[i], data=y.sub$z, target=target, y_title=scaled_title)
}

##### Now once the plots are ready show them in separate tabs
for( i in 1:length(genes) ){
  cat("\n#### ", genes[i], "\n")
  cat(renderTags(output_counts[[i]])$html)
  cat(renderTags(output_transform[[i]])$html)
  
  if ( tolower(params$norm) != "none" ) {
    cat(renderTags(output_norm[[i]])$html)
  }
  
  if ( any(runChunk && batch_rm_status) ) {
    cat(renderTags(output_batch[[i]])$html)
  }
  
  cat(renderTags(output_z[[i]])$html)
  cat("\n***\n")
}

##### Detach plotly package. Otherwise it clashes with other graphics devices
detach("package:plotly", unload=FALSE)
```

### Table

`r if ( tolower(params$norm) != "none" ) { c(paste0("Tables with counts data, ", params$transform, ", normalised ", params$transform, " (", params$norm, ") and ", if ( tolower(params$scaling) == "gene-wise" ) { c("z-score transformed") } else { c("centered") }, " (", z_scaling, ") ")) } else { c(paste0("Tables with counts data, ", params$transform, " and ", if ( tolower(params$scaling) == "gene-wise" ) { c("z-score transformed") } else { c("centered") }, " (", z_scaling, ") ")) }` values for each sample for selected gene(s).

`r if ( runChunk ) { c("**Counts**") } else { c("**Queried genes are not present in the input data!**") }`

```{r data_table_counts, comment = NA, message=FALSE, warning=FALSE, eval = runChunk}
##### Generate a table with expression values for selected genes
DT::datatable( data = round(t(datasets.list[[dataset]][["combined_data_sub"]][genes,]), digits = 1), filter="none", rownames = TRUE, extensions = c('Buttons','Scroller'), options = list(pageLength = 10, dom = 'Bfrtip', buttons = c('excel', 'csv', 'pdf','copy','colvis'), scrollX = TRUE, deferRender = TRUE, scrollY = 200, scroller = TRUE), width = 800, caption = htmltools::tags$caption( style = 'caption-side: top; text-align: left; color:grey; font-size:100% ;'), escape = FALSE) %>%
    DT::formatStyle( columns = names(t(datasets.list[[dataset]][["combined_data_sub"]])), `font-size` = '12px', 'text-align' = 'center' )
```

`r if ( runChunk ) { c(paste0("**", params$transform, "**")) } else { c(" ") }`

```{r data_table_transform, comment = NA, message=FALSE, warning=FALSE, eval = runChunk}
##### Generate a table with expression values for selected genes
if ( params$filter ) {
    
  DT::datatable( data = round(t(y.sub$filtered.transformed[genes,]), digits = 1), filter="none", rownames = TRUE, extensions = c('Buttons','Scroller'), options = list(pageLength = 10, dom = 'Bfrtip', buttons = c('excel', 'csv', 'pdf','copy','colvis'), scrollX = TRUE, deferRender = TRUE, scrollY = 200, scroller = TRUE), width = 800, caption = htmltools::tags$caption( style = 'caption-side: top; text-align: left; color:grey; font-size:100% ;'), escape = FALSE) %>%
    DT::formatStyle( columns = names(t(y.sub$filtered.transformed)), `font-size` = '12px', 'text-align' = 'center' )

} else {
    
  DT::datatable( data = round(t(y.sub$transformed[genes,]), digits = 1), filter="none", rownames = TRUE, extensions = c('Buttons','Scroller'), options = list(pageLength = 10, dom = 'Bfrtip', buttons = c('excel', 'csv', 'pdf','copy','colvis'), scrollX = TRUE, deferRender = TRUE, scrollY = 200, scroller = TRUE), width = 800, caption = htmltools::tags$caption( style = 'caption-side: top; text-align: left; color:grey; font-size:100% ;'), escape = FALSE) %>%
    DT::formatStyle( columns = names(t(y.sub$transformed)), `font-size` = '12px', 'text-align' = 'center' )
}
```

`r if ( tolower(params$norm) != "none" && runChunk ) { paste0("**Normalised ", params$transform, " (", params$norm, ")**") } else { c(" ") }`

```{r data_table_normalised, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6, eval = runChunk}
##### Generate a table with expression values for selected genes
if ( tolower(params$norm) != "none" ) {
    
  DT::datatable( data = round(t(y.sub$norm[genes,]), digits = 1), filter="none", rownames = TRUE, extensions = c('Buttons','Scroller'), options = list(pageLength = 10, dom = 'Bfrtip', buttons = c('excel', 'csv', 'pdf','copy','colvis'), scrollX = TRUE, deferRender = TRUE, scrollY = 200, scroller = TRUE), width = 800, caption = htmltools::tags$caption( style = 'caption-side: top; text-align: left; color:grey; font-size:100% ;'), escape = FALSE) %>%
    DT::formatStyle( columns = names(t(y.sub$norm)), `font-size` = '12px', 'text-align' = 'center' )
}
```

`r if ( any(runChunk && batch_rm_status) ) { c("**Batch-effects corrected**") } else { c(" ") }`

```{r data_table_batch_corrected, comment = NA, message=FALSE, warning=FALSE, eval = any(runChunk && batch_rm_status)}
##### Generate a table with expression values for selected genes
DT::datatable( data = round(t(datasets.list[[dataset]][["batch_effect_corrected"]][genes,]), digits = 1), filter="none", rownames = TRUE, extensions = c('Buttons','Scroller'), options = list(pageLength = 10, dom = 'Bfrtip', buttons = c('excel', 'csv', 'pdf','copy','colvis'), scrollX = TRUE, deferRender = TRUE, scrollY = 200, scroller = TRUE), width = 800, caption = htmltools::tags$caption( style = 'caption-side: top; text-align: left; color:grey; font-size:100% ;'), escape = FALSE) %>%
    DT::formatStyle( columns = names(t(datasets.list[[dataset]][["batch_effect_corrected"]])), `font-size` = '12px', 'text-align' = 'center' )

```

`r if ( runChunk ) { c(paste0("**", scaled_title, "**")) } else { c(" ") }`

```{r data_table_z, comment = NA, message=FALSE, warning=FALSE, eval = runChunk}
##### Generate a table with expression values for selected genes
DT::datatable( data = round(t(y.sub$z[genes,]), digits = 1), filter="none", rownames = TRUE, extensions = c('Buttons','Scroller'), options = list(pageLength = 10, dom = 'Bfrtip', buttons = c('excel', 'csv', 'pdf','copy','colvis'), scrollX = TRUE, deferRender = TRUE, scrollY = 200, scroller = TRUE), width = 800, caption = htmltools::tags$caption( style = 'caption-side: top; text-align: left; color:grey; font-size:100% ;'), escape = FALSE) %>%
    DT::formatStyle( columns = names(t(y.sub$z)), `font-size` = '12px', 'text-align' = 'center' )

```

***

## Data processing effects {.tabset}

`r if ( tolower(params$norm) != "none" ) { c(paste0("Scatter-plots illustrating the effect of transformation, normalisation and ", if ( tolower(params$scaling) == "gene-wise" ) { c("z-score transformation") } else { c("centering") }, " (", z_scaling, ") on the ", params$transform, " data.")) } else { c(paste0("Scatter-plots illustrating the effect of transformation ", if ( tolower(params$scaling) == "gene-wise" ) { c("z-score transformation") } else { c("centering") }, " (", z_scaling, ") on the ", params$transform, " data.")) }`

`r if ( !runChunk ) { c("**None of the queried genes are not present in the input data**.") } else { c("") }`

```{r comparison_plots, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 5*(norm.height+1), eval = runChunk, results="asis"}
##### Plot expression distribution in transfromed and normalised data for selected genes
##### Create a list for htmlwidgets
output_transform <- list()
output_norm <- list()
output_batch <- list()
output_z <- list()

##### For each gene generate corresponding set of plots
for ( i in 1:length(genes) ) {
  
  ##### For normalisation ON
  if ( tolower(params$norm) != "none" ) {
    
    ##### Check the effect of data transformation
    output_transform[[i]] <- comparePlot(genes=genes[i], dataset1=datasets.list[[dataset]][["combined_data_sub"]], dataset2=y[["comb"]]$norm, main_title="", x_title="Counts", y_title=paste0("Normalised ", params$transform, " (", params$norm, ")"), sampleName=samples )
    
    ##### Check the effect of data normalisation
    output_norm[[i]] <- comparePlot(genes=genes[i], dataset1=y[["comb"]]$norm, dataset2=transformed.data, main_title="", x_title=paste0("Normalised ", params$transform, " (", params$norm, ")"), y_title=params$transform, sampleName=samples )
    
    if ( batch_rm_status ) {
      
      ##### Check the effect of data batch-effect correction
      output_batch[[i]] <- comparePlot(genes=genes[i], dataset1=datasets.list[[dataset]][["batch_effect_corrected"]], dataset2=transformed.data, main_title="", x_title=paste0("Batch-effects corrected ", params$transform), y_title=paste0("Normalised ", params$transform, " (", params$norm, ")"), sampleName=samples )
      
      ##### Check the effect of data Z-score transformation/centering
    output_z[[i]] <- comparePlot(genes=genes[i], dataset1=y[["comb"]]$z, dataset2=datasets.list[[dataset]][["batch_effect_corrected"]], main_title="", x_title=scaled_title, y_title=paste0("Batch-effects corrected ", params$transform), sampleName=samples )
    
    } else {
      
      ##### Check the effect of data Z-score transformation/centering
    output_z[[i]] <- comparePlot(genes=genes[i], dataset1=y[["comb"]]$z, dataset2=datasets.list[[dataset]][["batch_effect_corrected"]], main_title="", x_title=scaled_title, y_title=paste0("Normalised ", params$transform, " (", params$norm, ")"), sampleName=samples )
    }
      
  ##### For normalisation OFF
  } else {
    
    if ( batch_rm_status ) {
      
      ##### Check the effect of data batch-effect correction
      output_batch[[i]] <- comparePlot(genes=genes[i], dataset1=datasets.list[[dataset]][["batch_effect_corrected"]], dataset2=transformed.data, main_title="",  x_title=paste0("Batch-effects corrected ", params$transform), y_title=paste0("Normalised ", params$transform, " (", params$norm, ")"), sampleName=samples )
      
      ##### Check the effect of data Z-score transformation/centering
      output_z[[i]] <- comparePlot(genes=genes[i], dataset1=y[["comb"]]$z, dataset2=datasets.list[[dataset]][["batch_effect_corrected"]], main_title="", x_title=scaled_title, y_title=paste0("Batch-effects corrected ", params$transform), sampleName=samples )
    
    } else {
    
      ##### Check the effect of data Z-score transformation/centering
      output_z[[i]] <- comparePlot(genes=genes[i], dataset1=y[["comb"]]$z, dataset2=datasets.list[[dataset]][["batch_effect_corrected"]], main_title="", x_title=scaled_title, y_title="Counts", sampleName=samples )
    }
  }
}

##### Now once the plots are ready show them in separate tabs
for( i in 1:length(genes) ){
  
  ##### For normalisation ON
  if ( tolower(params$norm) != "none" ) {
    cat("\n### ", genes[i], "\n")
    cat(renderTags(output_transform[[i]])$html)
    cat(renderTags(output_norm[[i]])$html)
    
    if ( batch_rm_status ) {
      cat(renderTags(output_batch[[i]])$html)
    }
    
    cat(renderTags(output_z[[i]])$html)
    cat("\n***\n")
    
  ##### For normalisation OFF
  } else {
    cat("\n### ", genes[i], "\n")
    cat(renderTags(output_transform[[i]])$html)
    
    if ( batch_rm_status ) {
      cat(renderTags(output_batch[[i]])$html)
    }
    cat(renderTags(output_z[[i]])$html)
    cat("\n***\n")
  }
}
```

***

## Expression distributions {.tabset}

`r if ( tolower(params$norm) != "none" ) { c(paste0("Plots illustrating counts data, ", params$transform, ", normalised ", params$transform, " (", params$norm, ") and ", if ( tolower(params$scaling) == "gene-wise" ) { c("z-score transformed") } else { c("centered") }, " (", z_scaling, ") data distributions for selected gene(s)")) } else { c(paste0("Plots illustrating counts data, ", params$transform, " and ", if ( tolower(params$scaling) == "gene-wise" ) { c("z-score transformed") } else { c("centered") }, " (", z_scaling, ") data distributions for selected gene(s)")) }` along with simulated normal, binomial (p=0.25 and p=0.75) and bimodal distributions (computed based on the input data).

`r if ( !runChunk ) { c("**None of the queried genes are not present in the input data**.") } else { c("") }`

```{r prep_data_for_plotting_distr, comment = NA, message=FALSE, warning=FALSE, eval = runChunk}
if ( params$filter ) {
  transformed.data <- y.sub$filtered.transformed
} else {
  transformed.data <- y.sub$transformed
}
```

```{r expr_dist_plot, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 5*(norm.height+1), eval = runChunk, results="asis"}
##### Plot expression distribution in transfromed and normalised data for selected genes
##### Create a list for htmlwidgets
output_counts <- list()
output_transform <- list()
output_norm <- list()
output_batch <- list()
output_z <- list()

##### For each gene generate corresponding set of plots
for ( i in 1:length(genes) ) {
  
  ##### Counts data
  output_counts[[i]] <- densityPlot(genes=genes[i], data=datasets.list[[dataset]][["combined_data_sub"]], main_title="", x_title="Counts", sampleName=samples, distributions = c("normal", "binomial",  "bimodal") )
  
  ##### Transformed data
  output_transform[[i]] <- densityPlot(genes=genes[i], data=transformed.data, main_title="", x_title=params$transform, sampleName=samples, distributions = c("normal", "binomial",  "bimodal") )
    
  ##### Normalised data 
  if ( tolower(params$norm) != "none" ) {

    output_norm[[i]] <- densityPlot(genes=genes[i], data=y.sub$norm, main_title="", x_title=paste0("Normalised ", params$transform, " (", params$norm, ")"), sampleName=samples, distributions = c("normal", "binomial", "bimodal") ) 
  }
  
  ##### Check the effect of data batch-effect correction
  if ( batch_rm_status ) {
    output_batch[[i]] <- densityPlot(genes=genes[i], data=datasets.list[[dataset]][["batch_effect_corrected"]], main_title="", x_title="Batch-effects corrected", sampleName=samples, distributions = c("normal", "binomial", "bimodal") ) 
  }
    
  ##### Z-transformed data
  output_z[[i]] <- densityPlot(genes=genes[i], data=y.sub$z, main_title="", x_title=scaled_title, sampleName=samples, distributions = c("normal", "binomial",  "bimodal") )
}

##### Now once the plots are ready show them in separate tabs
for( i in 1:length(genes) ){
  cat("\n### ", genes[i], "\n")
  cat(renderTags(output_counts[[i]])$html)
  cat(renderTags(output_transform[[i]])$html)
  
  if ( tolower(params$norm) != "none" ) {
    cat(renderTags(output_norm[[i]])$html)
  }
  
  if ( batch_rm_status ) {
    cat(renderTags(output_batch[[i]])$html)
  }
  cat(renderTags(output_z[[i]])$html)
  cat("\n***\n")
}
```

***

## Addendum

<details>
<summary>Parameters</summary>
<font size="2">

```{r params_info, comment = NA}
for ( i in 1:length(params) ) {

  cat(paste("Parameter: ", names(params)[i], "\nValue: ", paste(unlist(params[i]), collapse = ","), "\n\n", sep=""))
}
```

</font>
</details>

<details>
<summary>Reporter details</summary>
<font size="2">

```{r reporter_details, comment = NA}
cat(paste0("The report was generated by \"", Sys.info()[ "user"], "\" using \"",  Sys.info()[ "nodename"], "\" node and \"",  Sys.info()[ "sysname"], "\" operating system."))
```

</font>
</details>

<details>
<summary>Session information</summary>
<font size="2">

```{r session_info, comment = NA}
devtools::session_info()
```

</font>
</details>