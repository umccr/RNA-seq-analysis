---
title: "Combined expression data from multiple samples"
author: "UMCCR"
date: "`r format(Sys.time(), '%d %B, %Y')`"
params:
  exprDir: 
  exprFile: 
  annotFile: 
  annotFeatures: 'Target'
  transform: 'TPM'
  filter: TRUE
  filter_perc: 10
  norm: 'quantile'
  log: TRUE
  output_dir: 
  results_name: 
  top_genes: 400
  goi: 'none'
  seed: 99999999
  grch_version: 38
  ensembl_version: 86
output:
  html_document:
    keep_md: yes
    code_download: true
    code_folding: hide
    theme: readable
    toc: true
    toc_float: true
  rmdformats::material:
    highlight: kate
---

Results from combining expression data (**`r params$exprFile`**) from different samples. This includes filtering out genes with low counts `r if ( !params$filter ) { c("(this step is skipped)") }`, transformation (`r params$transform` method, `r if ( !params$log ) { c("with no log-transformation") } else if ( params$log ) { c("followed by log2-transformation") }`) and normalisation (`r params$norm`). The pipeline is based on recommendations from *[RNAseq123](https://master.bioconductor.org/packages/release/workflows/vignettes/RNAseq123/inst/doc/limmaWorkflow.html){target="_blank"}* package.


```{r seed}
##### Set the seed
if ( params$seed == 99999999 ) {
  seed <- sample(0:99999999, 1, replace = TRUE)
} else {
  seed <- params$seed
}

set.seed(seed)
```

<details>
<summary>Input parameters</summary>
<font size="2">

* **exprDir**: `r params$exprDir`
* **exprFile**: `r params$exprFile`
* **annotFile**: `r params$annotFile`
* **transform**: `r params$transform`
* **filter**: `r params$filter`
* **filter_perc**: `r params$filter_perc`
* **norm**: `r params$norm`
* **log**: `r params$log`
* **results_name**: `r params$results_name`
* **top_genes**: `r params$top_genes`
* **goi**: `r params$goi`
* **grch_version**: `r params$grch_version`
* **ensembl_version**: `r params$ensembl_version`
* **seed**: `r seed`

</font> 
</details>

```{r load_libraries, warning=FALSE}
### Load libraries
suppressMessages(library(preprocessCore))
suppressMessages(library(edgeR))
suppressMessages(library(ComplexHeatmap))
suppressMessages(library(NOISeq))
suppressMessages(library(package=paste0("EnsDb.Hsapiens.v", params$ensembl_version), character.only = TRUE))
suppressMessages(library(htmltools))
```

```{r define_functions, comment=NA, message=FALSE, warning=FALSE}
### Define functions
##### Create 'not in' operator
"%!in%" <- function(x,table) match(x,table, nomatch = 0) == 0

##### Assign colours to different groups
getTargetsColours <- function(targets) {
  
##### Predefined selection of colours for groups
targets.colours <- c("red","blue","green","darkgoldenrod","darkred","deepskyblue", "coral", "cornflowerblue", "chartreuse4", "bisque4", "chocolate3", "cadetblue3", "darkslategrey", "lightgoldenrod4", "mediumpurple4", "orangered3","indianred1","blueviolet","darkolivegreen4","darkgoldenrod4","firebrick3","deepskyblue4", "coral3", "dodgerblue1", "chartreuse3", "bisque3", "chocolate4", "cadetblue", "darkslategray4", "lightgoldenrod3", "mediumpurple3", "orangered1")
  f.targets <- factor(targets)
  vec.targets <- targets.colours[1:length(levels(f.targets))]
  targets.colour <- rep(0,length(f.targets))
  for(i in 1:length(f.targets))
    targets.colour[i] <- vec.targets[ f.targets[i]==levels(f.targets)]
  
  return( list(vec.targets, targets.colour) )
}
##### Calculate TPM from RPKM (from http://luisvalesilva.com/datasimple/rna-seq_units.html )
tpm_from_rpkm <- function(x) {
  rpkm.sum <- colSums(x)
  return(t(t(x) / (1e-06 * rpkm.sum)))
}

##### A wrapper to saveWidget which compensates for arguable BUG in saveWidget which requires `file` to be in current working directory (see post https://github.com/ramnathv/htmlwidgets/issues/299 )
saveWidgetFix <- function ( widget, file, ...) {
  wd<-getwd()
  on.exit(setwd(wd))
  outDir<-dirname(file)
  file<-basename(file)
  setwd(outDir);
  htmlwidgets::saveWidget(widget,file=file,...)
}

##### function for suppressing output from cat()
quiet <- function(x) { 
  sink(tempfile()) 
  on.exit(sink()) 
  invisible(force(x)) 
}
```

```{r load_data, message=FALSE, warning=FALSE}
##### Read in expression data and associated sample annotation files
data <- read.table(paste(params$exprDir, params$exprFile, sep="/"), sep="\t", as.is=TRUE, header=TRUE, row.names = 1)
targetFile <- read.table(paste(params$exprDir, params$annotFile, sep="/"), sep="\t", as.is=TRUE, header=TRUE)

##### Make sure that there are no duplciated samples in the target file
targetFile <- targetFile[!duplicated(targetFile[,"Sample_name"]),]
rownames(targetFile) <- targetFile[,"Sample_name"]

##### Make syntactically valid names
colnames(data) <- make.names(colnames(data))
rownames(targetFile) <- make.names(rownames(targetFile))

##### Make sure that the target file contains info only about samples present in the data matrix
targetFile <- targetFile[ rownames(targetFile) %in% colnames(data),  ]

##### Make sure that the samples order in the data matrix is the same as in the target file. If the expression matrix contains data for additional samples then write the data subset (containing only samples from the target file) into a file
if ( !all( colnames(data) %in% rownames(targetFile) , na.rm = FALSE)  ) {
  
  data <- data[ , rownames(targetFile) ]

  ##### Save data subset into a file
  write.table(data, file=paste0(params$output_dir, "/", paste0(params$exprFile, ".subset.txt")), sep="\t", quote=FALSE, row.names=TRUE, col.names=NA, append = FALSE)
} else {
  data <- data[ , rownames(targetFile) ]
}

##### Set up annotation features to be used for plots
annotFeatures <- unique(c("Target", unlist(strsplit(params$annotFeatures, split=',', fixed=TRUE))))

##### Define genes of interest (if specified)
if ( params$goi != "none" ) {
  goi_list <- unique(read.table(params$goi, sep="\t", as.is=TRUE, header=FALSE, row.names=NULL, quote="")[,1])
  runGOI <- TRUE
} else {
  runGOI <- FALSE
}
```

`r c(paste0("In total **", ncol(data), "** samples were analysed."))`

***

## Exploratory data analysis {.tabset}

### Library size

Bar-plot illustrating library size for each sample.

```{r library_size_plot, message = FALSE, warning = FALSE, echo = TRUE, fig.width = 12, fig.height = 9}
suppressMessages(library(plotly))
##### Generate bar-plot for library size. The colours indicate sample groups, as provided in *Target* column in the sample annotation file

##### Assigne colours to targets and datasets
targets.colour <- getTargetsColours(targetFile$Target)

##### Prepare data frame
data.df <- data.frame(targetFile$Target, colnames(data), as.numeric(colSums(data)*1e-6))
colnames(data.df) <- c("Group","Sample", "Library_size")

##### The default order will be alphabetized unless specified as below
data.df$Sample <- factor(data.df$Sample, levels = data.df[["Sample"]])
p <- plot_ly(data.df, x = ~Sample, y = ~Library_size, color = ~Group, type = 'bar', colors = targets.colour[[1]], width = 800, height = 400) %>%
  layout(title = "", xaxis = list( tickfont = list(size = 10), title = ""), yaxis = list(title = "Library size (millions)"), margin = list(l=50, r=50, b=150, t=50, pad=4), autosize = F, legend = list(orientation = 'v', y = 0.5), showlegend=TRUE)

##### Print htmlwidget
p

##### Save the bar-plot as html (PLOTLY)
saveWidgetFix(as_widget(p), paste0(params$output_dir, "/", paste0(params$results_name, "_libSize.html")))

##### Detach plotly package. Otherwise it clashes with other graphics devices
detach("package:plotly", unload=FALSE)
```

***

### Biodetection plot

Plot presenting the biotypes and frequencies of genes detected in investigated samples. It is expected that most of the genes
will be protein-coding so detecting an enrichment of any other biotype could point to a potential contamination or at least provide information on the samples composition. The stripped and solid red bars correspond to the percentage of individual biotypes detected across all samples. The vertical green line separates the most abundant biotypes (in the left-hand side, corresponding to the left axis scale) from the rest (in the right-hand side, corresponding to the right axis scale).

```{r gene_annot_count_data, comment = NA, message=FALSE, warning=FALSE}
##### Convert data into a data frame to make the Ensembl ID and gene symbol matches (with merge function)
data.df <- as.data.frame(cbind(rownames(data), data))
colnames(data.df)[1] <- "ENSEMBL"

##### Get genes annotation and genomic locations
edb <- eval(parse(text = paste0("EnsDb.Hsapiens.v", params$ensembl_version)))
  
##### Get keytypes for gene SYMBOL
keys <- keys(edb, keytype="GENEID")
  
##### Get genes genomic coordiantes
gene_info <- ensembldb::select(edb, keys=keys, columns=c("GENEID", "GENEBIOTYPE", "GENENAME", "SEQNAME", "GENESEQSTART", "GENESEQEND"), keytype="GENEID")
names(gene_info) <- gsub("GENEID", "ENSEMBL", names(gene_info))
names(gene_info) <- gsub("GENENAME", "SYMBOL", names(gene_info))
  
##### Limit genes annotation to those genes for which sample expression measurments are available
gene_info <-  gene_info[ gene_info$ENSEMBL %in% data.df$ENSEMBL,  ]
  
##### Remove rows with duplicated ENSEMBL IDs
gene_info = gene_info[!duplicated(gene_info$ENSEMBL),]
rownames(gene_info) <- gene_info$ENSEMBL
  
##### Remove rows with duplicated gene symbols (Y_RNAs, SNORs, LINC0s etc)
gene_info = gene_info[!duplicated(gene_info$SYMBOL),]
  
##### Merge genes genomic coordinates info with their annotation and expression data
data.annot <- merge(gene_info, data.df, by = "ENSEMBL", all.x = FALSE)
rownames(data.annot) <- data.annot$ENSEMBL

##### Keep only genes fo which gene symbol is available
data.annot <- data.annot[!(is.na(data.annot$SYMBOL) | data.annot$SYMBOL==""), ]
rownames(data.annot) <- data.annot$SYMBOL
  
##### Save the annotated data matrix into a file
write.table(data.annot, file=paste0(params$output_dir, "/", paste0(params$results_name, "_annot.txt")), sep="\t", quote=FALSE, row.names=TRUE, col.names=NA, append = FALSE)

##### Clean the space
rm(data.df, edb, keys)
```

```{r biotype_detection, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6}
##### Make sure that only genes with available annotations are used for biotype detection
data_NOISeq <-  data[ rownames(data) %in% gene_info$ENSEMBL,  ]

##### Extract biotype info
biotype <- gene_info$GENEBIOTYPE
names(biotype) <- gene_info$ENSEMBL

##### NOTE, make sure that each biotype is represented by at least 1 read across all samples
biotype <- biotype[duplicated(biotype) | duplicated(biotype, fromLast=TRUE)]
data_NOISeq <-  data[ rownames(data) %in% names(biotype),  ]

##### Converting data into a NOISeq object
data_NOISeq <- readData(data = data_NOISeq, biotype = biotype, chromosome = as.data.frame(gene_info[ , c("SEQNAME", "GENESEQSTART", "GENESEQEND") ]), factors = data.frame(sample = colnames(data_NOISeq), group = rep("All", ncol(data_NOISeq))))

##### Biotype detection across all samples
biodetection_group <- quiet(NOISeq::dat(data_NOISeq, k = 0, type = "biodetection", factor = "group"))

biodetection_samples <- quiet(NOISeq::dat(data_NOISeq, k = 0, type = "biodetection", factor = NULL))

##### Generate biotype detection plots for all and each sample
explo.plot(biodetection_group, samples = "All", plottype = "persample")

##### ...and save the plots into a files
biotype_detection_dir <- paste(params$output_dir, "biotype_detection", sep = "/")

if ( !file.exists(biotype_detection_dir) ) {
  dir.create(biotype_detection_dir, recursive=TRUE)
}

pdf(paste0(biotype_detection_dir, "/biotype_detection.pdf"))
explo.plot(biodetection_group, samples = "All", plottype = "persample")
invisible(dev.off())

for ( i in 1:ncol(data_NOISeq) ) {
  pdf(paste0(biotype_detection_dir, "/", colnames(data_NOISeq)[i],"_biotype_detection.pdf"))
  explo.plot(biodetection_samples, samples = i, plottype = "persample")
  invisible(dev.off())
}
```

***

### Count distribution per biotype

Count distribution per biotype across all samples. At the upper part of the plot, the number of detected features within each biotype group is displayed. The values used for the boxplots (*y-axis*) are counts per million.

```{r count_per_biotype, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6}
##### Count distribution per biotype
countsbio_group = quiet(NOISeq::dat(data_NOISeq, type = "countsbio", factor = "group"))

countsbio_samples = quiet(NOISeq::dat(data_NOISeq, type = "countsbio", factor = NULL))

##### Generate count distribution per biotype plots for all and each sample
explo.plot(countsbio_group, toplot = 1, samples = "All", plottype = "boxplot")

##### ...and save the plots into a files
pdf(paste0(biotype_detection_dir, "/count_per_biotype.pdf"))
explo.plot(countsbio_group, toplot = 1, samples = "All", plottype = "boxplot")
invisible(dev.off())

for ( i in 1:ncol(data_NOISeq) ) {
  pdf(paste0(biotype_detection_dir, "/", colnames(data_NOISeq)[i],"_count_per_biotype.pdf"))
  explo.plot(countsbio_samples, samples = i, plottype = "boxplot")
  invisible(dev.off())
}
```

***

### Count distribution per sample

Distribution of counts in all samples. The values used for the boxplots (*y-axis*) are counts per million.

```{r count_per_sample, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6}
##### Generate count distribution per sample plot
explo.plot(countsbio_samples, toplot = 1, samples = NULL, plottype = "boxplot")

##### ...and save the plots into a files
pdf(paste0(biotype_detection_dir, "/count_per_sample.pdf"))
explo.plot(countsbio_samples, toplot = 1, samples = NULL, plottype = "boxplot")
invisible(dev.off())
```

***

### Saturation plot

The saturation plot shows the number of features in the genome detected with the actual sequencing depth in individual samples, as well as with higher and lower simulated sequencing depths. The lines show how the number of detected features increases with depth. *Y axis* illustrates the number of detected genes at each sequencing depth. The solid point in each line corresponds to the real sequencing depth. The other sequencing depths are simulated from this total sequencing depth. Up to 10 samples are displayed on one plot.
 
```{r saturation, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6}
##### Count distribution per biotype
saturation = quiet(NOISeq::dat(data_NOISeq, k = 0, ndepth = 7, type = "saturation"))

##### Generate saturation plots for all and each sample
##### ...and save the plots into a files
saturation_dir <- paste(params$output_dir, "saturation", sep = "/")

if ( !file.exists(saturation_dir) ) {
  dir.create(saturation_dir, recursive=TRUE)
}

##### Up to 12 samples can be displayed in this plot, so create more plots if more samples are analysed
if ( ncol(data_NOISeq) > 10 ) {
  
  last_plot <- as.numeric(ncol(data_NOISeq) %/% 10)
  last_plots <- as.numeric(ncol(data_NOISeq) %% 10)
  
  for (i in 1:as.numeric(ncol(data_NOISeq) %/% 10) ) {
    
    explo.plot(saturation, toplot = 1, samples = (i*10-9):(i*10))
    
    pdf(paste0(saturation_dir, "/saturation_", i, ".pdf"))
    explo.plot(saturation, toplot = 1, samples = (i*10-9):(i*10))
    invisible(dev.off())
  }
  
  if ( last_plots != 0 ) {
    
    explo.plot(saturation, toplot = 1, samples = (i*10-9):((i*10-9)+last_plot))
    
    pdf(paste0(saturation_dir, "/saturation_", i+1, ".pdf"))
    explo.plot(saturation, toplot = 1, samples = (i*10-9):((i*10-9)+last_plot))
    invisible(dev.off())

  }
} else {
  explo.plot(saturation, toplot = 1, samples = 1:ncol(data_NOISeq))
  
  pdf(paste0(saturation_dir, "/saturation_.pdf"))
  explo.plot(saturation, toplot = 1, samples = 1:ncol(data_NOISeq))
  invisible(dev.off())
}

for ( i in 1:ncol(data_NOISeq) ) {
  pdf(paste0(saturation_dir, "/", colnames(data_NOISeq)[i],"_saturation.pdf"))
  explo.plot(saturation, toplot = 1, samples = i)
  invisible(dev.off())
}
```

***

### Sensitivity plot

Features with low counts are, in general, less reliable and may introduce noise in the data that makes more difficult to extract the relevant information, for instance, the differentially expressed features. The sensitivity plot helps to decide the threshold to remove low-count features by indicating the proportion of such features that are present in the data. The bars show the percentage of features within each sample having more than 0 counts per million (CPM), or more than 1, 2, 5 and 10 CPM. The *horizontal lines* are the corresponding percentage of features with those CPM in at least one of the samples. In the upper side of the plot, the sequencing depth of each sample (in million reads) is given.
 
```{r sensitivity, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6}
##### Generate count distribution per sample plots for all and each sample
explo.plot(countsbio_samples, toplot = 1, samples = NULL, plottype = "barplot")

##### Generate saturation plots for all and each sample
##### ...and save the plots into a files
sensitivity_dir <- paste(params$output_dir, "sensitivity", sep = "/")

if ( !file.exists(sensitivity_dir) ) {
  dir.create(sensitivity_dir, recursive=TRUE)
}

##### ...and save the plots into a files
pdf(paste0(sensitivity_dir, "/sensitivity.pdf"))
explo.plot(countsbio_samples, toplot = 1, samples = NULL, plottype = "barplot")
invisible(dev.off())
```

***

## Data transformation and filtering

The read count data is converted into **`r params$transform`**s using *[edgeR](https://bioconductor.org/packages/release/bioc/html/edgeR.html){target="_blank"}* functions. `r if ( !params$filter ) { c("The option for filtering out genes with low counts is switched OFF") } else if ( params$filter ) { c("Genes with low counts were filtered out") }`. `r if ( !params$log ) { c("The data is not log-transformed") } else if ( params$log ) { c("The data is log2-transformed") }`. Plot(s) below present `r params$transform` data distribution.

```{r data_transformation_filtering, comment = NA, message=FALSE, warning=FALSE}
##### Filtering to remove low expressed genes. For differential expression and related analyses, gene expression is rarely considered at the level of raw counts since libraries sequenced at a greater depth will result in higher counts. Rather, it is common practice to transform raw counts onto a scale that accounts for such library size differences. Genes with very low counts across all libraries provide little evidence for differential expression. In the biological point of view, a gene must be expressed at some minimal level before it is likely to be translated into a protein or to be biologically important. In addition, the pronounced discretenes of these counts interferes with some of the statistical approximations that are used later in the pipeline. These genes should be filtered out prior to further analysis. Users should filter with CPM rather than filtering on the counts directly, as the latter does not account for differences in library sizes between samples. For instance for the CPM-transformed data we keep only genes that have CPM of 1
##### Transformation to CPM or TPM scale (see these blogs for details https://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/ and https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/ ).  CPM = Counts Per Million,  TPM = Transcripts Per Kilobase Million. 

##### CPM transformation and filtering
if ( params$filter && params$transform == "CPM" ) {
  
  ##### Create EdgeR DGEList object
  y <- edgeR::DGEList(counts=data)
  
  ##### Keep genes with CPM of at least 1 in more than user-defined percentage of samples
  #cat("The CPM of 1 (cut-off for removing low expressed genes) corresponds to", round(min(as.numeric(colSums(data)*1e-6)), digits=0), "reads in sample with the lowest sequencing depth, and", round(max(as.numeric(colSums(data)*1e-6)), digits=0), "reads in sample with the greatest sequencing depth\n")
  
  keep <- rowSums(cpm(y)>1) >= ncol(data)*params$filter_perc/100
  y$filtered <- y[keep, , keep.lib.sizes=FALSE]
  
  #cat(nrow(y$filtered$counts), "genes remained after filtering out of the", nrow(data), "genes in the input read count matrix\n\n")
  
  ##### Transform the raw-scale to CPM. Add small offset to each observation to avoid taking log of zero
  y$transformed <- edgeR::cpm(y, normalized.lib.sizes=FALSE, log=params$log, prior.count=0.25)
  y$filtered.transformed <- edgeR::cpm(y$filtered, normalized.lib.sizes=FALSE, log=params$log, prior.count=0.25)
  
##### CPM transformation without filtering
} else if ( !params$filter && params$transform == "CPM" ) {
  
  ##### Create EdgeR DGEList object
  y <- edgeR::DGEList(counts=data,  group=targetFile$Target)
  
  ##### Transform the raw-scale to CPM. Add small offset to each observation to avoid taking log of zero
  y$transformed <- edgeR::cpm(y, normalized.lib.sizes=FALSE, log=params$log, prior.count=0.25)
  
##### TPM data transformation. We can convert RPKM to TPM in two different ways: from pre-calculated RPKM, by diving by the sum of RPKM values, or directly from the normalized counts. Here we calculate TPM starting from RPKM values computed using edgeR's rpkm function ( from http://luisvalesilva.com/datasimple/rna-seq_units.html )
##### TPM transformation with filtering
} else if ( params$filter && params$transform == "TPM" ) {
  
  ##### Get genes lengths
  edb <- eval(parse(text = paste0("EnsDb.Hsapiens.v", params$ensembl_version)))
  gene.length <- lengthOf(edb, filter = GeneIdFilter(rownames(data)))
  
  ##### Check for which genes the lenght info is not available and remove them from the data
  genes.no_length <- rownames(data)[ rownames(data) %!in% names(gene.length)]
  data <- data[ rownames(data) %!in% genes.no_length, ]
  
  ##### Create EdgeR DGEList object
  y <- edgeR::DGEList(counts=data)
  
  ##### Convert data into RPKM
  y$transformed <- edgeR::rpkm(y, gene.length = gene.length, normalized.lib.sizes=FALSE, log=FALSE)
  
  ##### Keep genes with TPM of at least 0.2 in more than user-defined of samples
  keep <- rowSums(y$transformed>0.2) >= ncol(data)*params$filter_perc/100
  y$filtered <- y$counts[keep, ]
  y$filtered.transformed <- y$transformed[keep, ]

  if ( params$norm == "sizeFactors" ) {
    sizeFactors <- edgeR::equalizeLibSizes(y, dispersion=NULL, log=FALSE)
    y$norm <- edgeR::rpkm(sizeFactors$pseudo.counts, gene.length = gene.length, normalized.lib.sizes=FALSE, log=FALSE)
    
    ##### Keep genes with TPM of at least 0.2 in more than 10% of samples
    y$norm <- y$norm[keep, ]
  }
  
  ##### ... and then to TPM scale. Add small offset to each observation to avoid taking log of zero
  if ( params$log ) {
    
    y$transformed <- log2(tpm_from_rpkm(y$transformed+0.25))
    y$filtered.transformed <- log2(tpm_from_rpkm(y$filtered.transformed+0.25))
  
    if ( params$norm == "sizeFactors" ) {
      y$norm <- log2(tpm_from_rpkm(y$norm+0.25))
    }
    
  } else {
    y$transformed <- tpm_from_rpkm(y$transformed)
    y$filtered.transformed <- tpm_from_rpkm(y$filtered.transformed)
  }
  
##### TPM transformation without filtering
} else if ( !params$filter && params$transform == "TPM" ) {
  
  ##### Get genes lengths
  edb <- eval(parse(text = paste0("EnsDb.Hsapiens.v", params$ensembl_version)))
  gene.length <- lengthOf(edb, filter = GeneIdFilter(rownames(data)))
  
  ##### Check for which genes the lenght info is not available and remove them from the data
  genes.no_length <- rownames(data)[ rownames(data) %!in% names(gene.length)]
  data <- data[ rownames(data) %!in% genes.no_length, ]
  
  ##### Create EdgeR DGEList object
  y <- edgeR::DGEList(counts=data)
  
  ##### Convert data into RPKM
  y$transformed <- edgeR::rpkm(y, gene.length = gene.length, normalized.lib.sizes=FALSE, log=FALSE)
  
  if ( params$norm == "sizeFactors" ) {
    sizeFactors <- edgeR::equalizeLibSizes(y, dispersion=NULL, log=FALSE)
    y$norm <- edgeR::rpkm(sizeFactors$pseudo.counts, gene.length = gene.length, normalized.lib.sizes=FALSE, log=FALSE)
  }
  
  ##### ... and then to TPM scale. Add small offset to each observation to avoid taking log of zero
  if ( params$log ) {
    
    y$transformed <- log2(tpm_from_rpkm(y$transformed+0.25))
    
    if ( params$norm == "sizeFactors" ) {
      y$norm <- log2(tpm_from_rpkm(y$norm+0.25))
    }
    
  } else {
    y$transformed <- tpm_from_rpkm(y$transformed)
  }
}
```

```{r data_transformation_plot, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 6}
##### Collect the most extreme density values for set the x-axis and y-axis boundaries
den.x <- density(y$transformed[,1])$x
den.y <- density(y$transformed[,1])$y
  
for (i in 2:ncol(y$transformed)) {
    
  den <- density(y$transformed[,i])
  den.x <- sort(c(den.x, den$x))
  den.y <- sort(c(den.y, den$y))
}
  
if ( params$filter ) {

  par(mfrow=c(1,2))
  
  ##### Before filtering
  plot(density(y$transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed data (unfiltered)", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y$transformed)){
    den <- density(y$transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  
  ##### After filtering
  plot(density(y$filtered.transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed and filtered data", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y$filtered.transformed)){
    den <- density(y$filtered.transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  
  ##### Save the plot as pdf file
  pdf(paste0(params$output_dir, "/", paste0(params$results_name, "_filtering.pdf")), width=8, height=5)
  par(mfrow=c(1,2))
  
  ##### Before filtering
  plot(density(y$transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed data (unfiltered)", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y$transformed)){
    den <- density(y$transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  
  ##### After filtering
  plot(density(y$filtered.transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed and filtered data", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y$filtered.transformed)){
    den <- density(y$filtered.transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  invisible(dev.off())
  
} else {
  
  ##### Without filtering
  plot(density(y$transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed data (unfiltered)", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y$transformed)){
    den <- density(y$transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  
  ##### Save the plot as pdf file
  pdf(paste0(params$output_dir, "/", paste0(params$results_name, "_filtering.pdf")), width=8, height=5)
  ##### Without filtering
  plot(density(y$transformed[,1]), lwd=2, xlim=c(den.x[1],den.x[length(den.x)]), ylim=c(den.y[1],den.y[length(den.y)]), las=2, main="", xlab="", col=targets.colour[[2]][1])
  title(main="Transformed data (unfiltered)", xlab=params$transform)
  abline(v=0, lty=3)
  
  for (i in 2:ncol(y$transformed)){
    den <- density(y$transformed[,i])
    lines(den$x, den$y, lwd=2, col=targets.colour[[2]][i])
  }
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], bty="n", bg = "transparent")
  invisible(dev.off())
}
```

***

## Data normalisation

`r if ( tolower(params$norm) == "none" ) { c("No normalisation is performed") } else { c(paste0("During the sample preparation or sequencing process, external factors that are not of biological interest can affect the expression of individual samples. For example, samples processed in the first batch of an experiment can have higher expression overall when compared to samples processed in a second batch. It is assumed that all samples should have a similar range and distribution of expression values. Normalisation for sample-specific effects is required to ensure that the expression distributions of each sample are similar across the entire experiment. Normalisation is performed using ", params$norm, " method")) }`. 

`r if ( tolower(params$norm) != "none" ) { c(paste0("Box-plots below present ", params$transform, " data for individual samples, coloured by sample groups, before and after ", params$norm, " normalisation.")) }`

```{r data_normalisation_unnorm_vs_norm, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 16}
##### TMM normalsation. Trimmed mean of M-values (https://www.ncbi.nlm.nih.gov/pubmed/20196867) (TMM) is performed using the calcNormFactors function in edgeR. The normalisation factors calculated here are used as a scaling factor for the library sizes. TMM is the recommended for most RNA-Seq data where the majority (more than half) of the genes are believed not differentially expressed between any pair of the samples. It adjusts for RNA composition effect, calculates scaling factors for the library sizes with calcNormFactors function using trimmed mean of M-values (TMM) between each pair of samples. Note, that the raw read counts are used to calculate the normalisation factors

if ( params$transform == "CPM" ) {
  
  ##### Calculate normalization factors and  transformations from the raw-scale to CPM and normalisation using user-defined method
  if ( params$filter ) {
    
    y$noNorm <- y$filtered.transformed
    y$filtered$samples["norm.factors"] <- edgeR::calcNormFactors(y$filtered, method = params$norm)$samples["norm.factors"]
    y$norm <- edgeR::cpm(y$filtered, normalized.lib.sizes=TRUE, log=params$log, prior.count=0.25)
  
  } else {
    
    y$noNorm <- y$transformed
    y$samples["norm.factors"] <- edgeR::calcNormFactors(y, method = params$norm)$samples["norm.factors"]
    y$norm <- edgeR::cpm(y, normalized.lib.sizes=TRUE, log=params$log, prior.count=0.25)
  }
  
##### Quantile normalsation (from https://www.biostars.org/p/296992/ )
} else if ( params$transform == "TPM" ) {
  
  ##### Normalisation using quantile method
  if ( params$filter ) {
    
    y$filtered.transformed <- data.matrix(y$filtered.transformed) 
    y$noNorm <- y$filtered.transformed
    
    if ( params$norm != "sizeFactors" ) {
      if ( tolower(params$norm) != "none" ) {
        
        y$norm  <- normalize.quantiles(y$filtered.transformed, copy = TRUE)
        colnames(y$norm) <- colnames(y$filtered.transformed)
        rownames(y$norm) <- rownames(y$filtered.transformed)
        
      } else {
        y$norm  <- y$filtered.transformed
      }
    } 
  } else {
    
    y$noNorm <- y$transformed
    y$transformed <- data.matrix(y$transformed)
    
    if ( params$norm != "sizeFactors" ) {
      if ( tolower(params$norm) != "none" ) {
        
        y$norm  <- normalize.quantiles(y$transformed, copy = TRUE)
        colnames(y$norm) <- colnames(y$transformed)
        rownames(y$norm) <- rownames(y$transformed)
        
      } else {
        y$norm  <- y$transformed
      }
    }
  }
}
 
##### Plot expression distribution of samples for unnormalised and normalised data
par(mfrow=c(2,1), mar=c((max(nchar(colnames(y$noNorm)))+3)/2, 5, 3, 2))
  
##### Unnormalised data
boxplot(y$noNorm, col=targets.colour[[2]], main="", pch=".", las=2)
title(main="Unnormalised data", ylab=params$transform)
legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], horiz=TRUE, bg = "transparent", box.col="transparent")
  
##### Normalised data
if ( tolower(params$norm) != "none" ) {
  
  boxplot(y$norm, col=targets.colour[[2]], main="", pch=".", las=2)
  title(main=paste0("Normalised data (", params$norm, ")"), ylab=params$transform)
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], horiz=TRUE, bg = "transparent", box.col="transparent")
}
  
##### Save the plot as pdf file
pdf(paste0(params$output_dir, "/", paste0(params$results_name, "_normalisation.pdf")), width=8, height=14)
par(mfrow=c(2,1), mar=c(max(nchar(colnames(y$noNorm)))/2, 5, 3, 2))
  
##### Unnormalised data
boxplot(y$noNorm, col=targets.colour[[2]], main="", pch=".", las=2)
title(main="Unnormalised data", ylab=params$transform)
legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], horiz=TRUE, bg = "transparent", box.col="transparent")
  
##### Normalised data
if ( tolower(params$norm) != "none" ) {
  
  boxplot(y$norm, col=targets.colour[[2]], main="", pch=".", las=2)
  title(main=paste0("Normalised data (", params$norm, ")"), ylab=params$transform)
  legend("topright", legend=levels(factor(targetFile$Target)), fill=targets.colour[[1]], horiz=TRUE, bg = "transparent", box.col="transparent")
}
invisible(dev.off())
  
# #######################################################
# ##### Prepare expression data frame for plotting in plotly by adding samples annotation and converting the matrix into two column data frame
# ##### Un-normalised cpm data
# y$transformed.df <- as.data.frame(cbind(rep(rownames(y$transformed), ncol(y$transformed)), rep(colnames(y$transformed), each=nrow(y$transformed)), rep(as.vector(y$filtered$samples$group), each=nrow(y$transformed)), as.numeric(y$transformed)))
# colnames(y$transformed.df) <- c("Gene", "Sample", "Group", "cpm")
# 
# ##### Normalised cpm data
# y$norm.transformed.df <- as.data.frame(cbind(rep(rownames(y$norm.transformed), ncol(y$norm.transformed)), rep(colnames(y$norm.transformed), each=nrow(y$norm.transformed)), rep(as.vector(y$norm$samples$group), each=nrow(y$norm.transformed)), as.numeric(y$norm.transformed)))
# colnames(y$norm.transformed.df) <- c("Gene", "Sample", "Group", "cpm")
# 
# 
# p <- plot_ly(width = 800, height = 600) 
# 
# for ( i in 1:12 ) {
#  p <- add_trace(p, y = y$transformed[,i], type = 'box', name = colnames(y$transformed)[i], jitter = 0.3, pointpos = 0, boxpoints = 'outliers',
#         marker = list(color = 'rgb(9,56,125)'),
#         line = list(color = 'rgb(9,56,125)'),
#         showlegend=FALSE)
#   }
# 
# ##### Save the box-plot as html
# saveWidgetFix(as_widget(p), paste0(params$output_dir, "/", paste0(params$results_name, "_", params$transform, "_", params$norm, "_normalisation.html")))
########################################################
```

```{r library_size_norm_plot, comment = NA, message=FALSE, warning=FALSE, echo = TRUE, fig.width = 8, fig.height = 3, results="asis"}
suppressMessages(library(plotly))

lib_size_plot <- list()

##### Generate bar-plot for library size again if sizeFactors normalisation was used to see if it works
if ( params$norm == "sizeFactors" ) {

  ##### Prepare data frame
  data.df <- data.frame(targetFile$Target, colnames(y$norm), as.numeric(colSums(y$norm)*1e-6))
  colnames(data.df) <- c("Group","Sample", "Library_size")
    
  ##### The default order will be alphabetized unless specified as below
  data.df$Sample <- factor(data.df$Sample, levels = data.df[["Sample"]])
  lib_size_plot[[1]] <- plot_ly(data.df, x = ~Sample, y = ~Library_size, color = ~Group, type = 'bar', colors = targets.colour[[1]], width = 800, height = 400) %>%
    layout(title = "", xaxis = list( tickfont = list(size = 10), title = ""), yaxis = list(title = "Library size (millions)"), margin = list(l=50, r=50, b=150, t=50, pad=4), autosize = F, legend = list(orientation = 'v', y = 0.5), showlegend=TRUE)
}

if ( length(lib_size_plot) == 1 ) {
  cat("\n<details>\n")
  cat("\n<summary>Normalised library size plot</summary>\n")
  cat("<font size=\"2\">\n")
  cat(renderTags(lib_size_plot[[1]])$html)
  
  cat("\n</font>\n")
  cat("\n</details>\n")
  
  ##### Save the bar-plot as html (PLOTLY)
  saveWidgetFix(lib_size_plot[[1]], file = paste0(params$output_dir, "/", paste0(params$results_name, "_library_size_norm.html")), selfcontained = TRUE)
}
```

***

## Clustering analysis {.tabset .tabset-fade}

### PCA {.tabset .tabset-fade}

Principal component analysis (PCA) transforms the data into a coordinate system and presents them in an orthogonal projection. This reduces the dimensionality of the data and facilitates exploration of their global structure, as well as the key *components* of variation of the data. The colours indicate sample groups. **`r params$top_genes` genes** with the highest expression variance across all samples were use for PCA.

#### 2D plot

Scatter plot of the first 2 principal components (PCs) constituting the primary source of variation in the data.

```{r PCA_plot_2D, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 8}
suppressMessages(library(plotly))

if ( length(targetFile$Target) > 2 ) {
  ##### Keep only genes with variance > 0 across all samples
  rsd <- apply(y$norm,1,sd)
  y$norm.subset <- y$norm[rsd>0,]
  rsd <- rsd[rsd>0]
  
  if ( nrow(y$norm.subset) < params$top_genes ) {
      sel<-order(rsd, decreasing=TRUE)[1:nrow(y$norm.subset)]
  } else {
      sel<-order(rsd, decreasing=TRUE)[1:params$top_genes]
  }
  
  ##### Subset genes
  y$norm.subset <- data.frame(y$norm.subset[sel,])

  ##### Perform PCA
  y$norm.subset_pca <- prcomp(t(y$norm.subset), scale=FALSE)
  
  ##### Get variance importance for all principal components
  importance_pca <- summary(y$norm.subset_pca)$importance[2,]
  importance_pca <- paste(round(100*importance_pca, 2), "%", sep="")
  names(importance_pca) <- names(summary(y$norm.subset_pca)$importance[2,])
    
  ##### Prepare data frame
  y$norm.subset_pca.df <- data.frame(targetFile$Target, y$norm.subset_pca$x[,"PC1"], y$norm.subset_pca$x[,"PC2"], y$norm.subset_pca$x[,"PC3"])
  colnames(y$norm.subset_pca.df) <- c("Target", "PC1", "PC2", "PC3")
  
  ##### Generate PCA 2-D plot
  p <- plot_ly(y$norm.subset_pca.df, x = ~PC1, y = ~PC2, color = ~Target, text=paste(targetFile$Target, rownames(y$norm.subset_pca.df), sep=": "), colors = targets.colour[[1]], type='scatter', mode = "markers", marker = list(size=10, opacity = 0.7), width = 600, height = 400) %>%
  layout(title = "", xaxis = list(title = paste( "PC1", " (",importance_pca["PC1"],")",sep="")), yaxis = list(title = paste( "PC2", " (",importance_pca["PC2"],")",sep="")), margin = list(l=50, r=50, b=50, t=20, pad=4), autosize = FALSE, showlegend = TRUE, legend = list(orientation = "v", y = 0.9))

  ##### Save PCA plot as html
  saveWidgetFix(as_widget(p), paste0(params$output_dir, "/", paste0(params$results_name, "_PCA_2d.html")))
  
  p
}
```

`r if ( length(targetFile$Target) < 3 ) { c("**Only two samples were analysed!**") }`

***

#### 3D plot

Scatter plot of the first 3 principal components (PCs) constituting the primary source of variation in the data.

```{r PCA_plot_3D, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 8}
##### Generate PCA 3-D plot
if ( length(targetFile$Target) > 2 ) {
  p <- plot_ly(y$norm.subset_pca.df, x = ~PC1, y = ~PC2, z = ~PC3, color = ~Target, text=paste(targetFile$Target, rownames(y$norm.subset_pca.df), sep=": "), colors = targets.colour[[1]], type='scatter3d', mode = "markers", marker = list(size=6, opacity = 0.7), width = 600, height = 600) %>%
  layout(title = "", scene = list(xaxis = list(title = paste( "PC1", " (",importance_pca["PC1"],")",sep="")), yaxis = list(title = paste( "PC2", " (",importance_pca["PC2"],")",sep="")), zaxis = list(title = paste( "PC3", " (",importance_pca["PC3"],")",sep=""))) , margin = list(l=50, r=50, b=50, t=10, pad=4), autosize = FALSE, showlegend = TRUE, legend = list(orientation = "v", y = 0.7))
  
  ##### Save PCA plot as html
  saveWidgetFix(p, file = paste0(params$output_dir, "/", paste0(params$results_name, "_PCA_3d.html")))
  
  p
  
}
```

`r if ( length(targetFile$Target) < 3 ) { c("**Only two samples were analysed!**") }`

***

#### Pariwise plot

Scatter plots for all combinations between the first 5 principal components (PCs) to help determine which PCs explain the biological and/or potential batch effects.

```{r PCA_pairwise_plot, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 8}
##### Plot all combinations between the first 5 PCs
##### Preapre colours for plot exis
axis = list(showline=FALSE, zeroline=FALSE, gridcolor='#ffff', ticklen=5)

if ( length(targetFile$Target) > 4 ) {
  
  p <- as.data.frame(y$norm.subset_pca$x[,1:5]) %>%
    plot_ly(width = 800, height = 800) %>%
    add_trace( type = 'splom', dimensions = list(
        list(label='PC1', values=~PC1), list(label='PC2', values=~PC2), list(label='PC3', values=~PC3), list(label='PC4', values=~PC4), list(label='PC5', values=~PC5)
      ),
    text=paste(targetFile$Target, rownames(y$norm.subset_pca$x), sep=": "),
      marker = list( color = targets.colour[[2]], size = 7, opacity = 0.7
      )
    ) %>%
    layout(
      title= "",
      hovermode="closest",
      plot_bgcolor="rgba(240,240,240, 0.95)",
      xaxis=list(domain=NULL, showline=F, zeroline=F, gridcolor='#ffff', ticklen=4),
      yaxis=list(domain=NULL, showline=F, zeroline=F, gridcolor='#ffff', ticklen=4),
      xaxis2=axis, xaxis3=axis, xaxis4=axis, xaxis5=axis, yaxis2=axis, yaxis3=axis, yaxis4=axis, yaxis5=axis, legend = list(orientation = "v", y = 0.9)
  )
  
  ##### Save pairwise PCA plot as html
  saveWidgetFix(p, file = paste0(params$output_dir, "/", paste0(params$results_name, "_PCA_pairwise.html")))
  
  p
  
  ##### Plot all combinations between the first 5 PCs
  #pairs(y$norm.subset_pca$x[,1:5], pch=16, col=targets.colour[[2]])
  ##### Save the plot as pdf file
  #pdf(paste0(params$output_dir, "/", paste0(params$results_name, "_PCA_pairwise.pdf")), width=10, height=10)
  #pairs(y$norm.subset_pca$x[,1:5], pch=16, col=targets.colour[[2]])
  #invisible(dev.off())
}
```

`r if ( length(targetFile$Target) < 5 ) { c("**Less than five samples were analysed!**") }`

***

#### Scree plot

Scree plot presenting the fraction of total variance (y-axis) attributed to each PC (x-axis). The PCs are ordered by decreasing order of contribution to total variance. 

```{r Scree_plot, comment = NA, message=FALSE, warning=FALSE, fig.width = 12, fig.height = 8}
##### Generate scree plot
##### Prepare data frame
if ( length(targetFile$Target) > 2 ) {
  
  y$norm.subset_scree.df <- data.frame(paste0("PC ", c(1:length(importance_pca))), as.numeric(gsub("%", "",importance_pca)))
  colnames(y$norm.subset_scree.df) <- c("PC", "Variances")
  
  ##### The default order will be alphabetized unless specified as below
  y$norm.subset_scree.df$PC <- factor(y$norm.subset_scree.df$PC, levels = y$norm.subset_scree.df[["PC"]])
  p <- plot_ly(y$norm.subset_scree.df, x = ~PC, y = ~Variances, type = 'bar', width = 600, height = 400) %>%
    layout(title = "The variances captured by principal components", xaxis = list(title = ""), margin = list(l=50, r=50, b=100, t=100, pad=4), autosize = F)
  
  ##### Save scree plot as html
  saveWidgetFix(p, file = paste0(params$output_dir, "/", paste0(params$results_name, "_scree_plot.html")))
  
  p
}

##### Detach plotly package. Otherwise it clashes with other graphics devices
detach("package:plotly", unload=FALSE)
```

`r if ( length(targetFile$Target) < 3 ) { c("**Only two samples were analysed!**") }`

***

### Heatmap {.tabset .tabset-fade}

`r if ( runGOI ) { c("#### Most variable genes") }`

Heatmap presenting expression levels of **`r params$top_genes` genes** (*y-axis*) with the highest expression variance across all samples (*x-axis*).

```{r gene_annotation, comment = NA, message=FALSE, warning=FALSE}
##### Convert data into a data frame to make the Ensembl ID and gene symbol matches (with merge function)
data <- y$norm
data.df <- as.data.frame(cbind(rownames(data), data))
colnames(data.df)[1] <- "ENSEMBL"

##### Get genes annotation and genomic locations
edb <- eval(parse(text = paste0("EnsDb.Hsapiens.v", params$ensembl_version)))
  
##### Get keytypes for gene SYMBOL
keys <- keys(edb, keytype="GENEID")
  
##### Get genes genomic coordiantes
gene_info <- ensembldb::select(edb, keys=keys, columns=c("GENEID", "GENENAME"), keytype="GENEID")
names(gene_info) <- gsub("GENEID", "ENSEMBL", names(gene_info))
names(gene_info) <- gsub("GENENAME", "SYMBOL", names(gene_info))
  
##### Limit genes annotation to those genes for which sample expression measurments are available
gene_info <-  gene_info[ gene_info$ENSEMBL %in% data.df$ENSEMBL,  ]
  
##### Remove rows with duplicated ENSEMBL IDs
gene_info = gene_info[!duplicated(gene_info$ENSEMBL),]
rownames(gene_info) <- gene_info$ENSEMBL
  
##### Remove rows with duplicated gene symbols (Y_RNAs, SNORs, LINC0s etc)
gene_info = gene_info[!duplicated(gene_info$SYMBOL),]
  
##### Merge genes genomic coordinates info with their annotation and expression data
data.annot <- merge(gene_info, data.df, by = "ENSEMBL", all.x = FALSE)
rownames(data.annot) <- data.annot$ENSEMBL

##### Keep only genes fo which gene symbol is available
data.annot <- data.annot[!(is.na(data.annot$SYMBOL) | data.annot$SYMBOL==""), ]
rownames(data.annot) <- data.annot$SYMBOL
  
##### Get data matrix with gene symbols
data <- apply(data.annot[, colnames(data)], 2, as.numeric)
rownames(data) <- data.annot$SYMBOL

##### Clean the space
rm(data.df, edb, keys)
```

```{r heatmap, warning = FALSE, echo = TRUE, message = FALSE, results = 'hide', fig.width = 12, fig.height = 10}
##### Keep only genes with variance > 0 across all samples
rsd <- apply(data,1,sd)
data <- data[rsd>0,]
rsd <- rsd[rsd>0]

if ( nrow(data) < params$top_genes ) {
    sel<-order(rsd, decreasing=TRUE)[1:nrow(data)]
} else {
    sel<-order(rsd, decreasing=TRUE)[1:params$top_genes]
}

##### Subset genes
data.h <- data.frame(data[sel,])

##### Prepare heatmap annotation (samples)
Target.col  <- targets.colour[[1]]
names(Target.col) <- sort(unique(targetFile$Target))
ha = HeatmapAnnotation(df = targetFile[, colnames(targetFile) %in% annotFeatures, drop = FALSE], col = list(Target = Target.col ))

##### Cluster genes
hc <- hclust(as.dist(1-cor(data.h, method="pearson")), method="ward.D2")

##### Cluster samples
hr <- hclust(as.dist(dist(data.h, method="euclidean")), method="ward.D2")

##### Generate heatmap (complexHeatmap)
if ( length(unique(targetFile$Target)) > 1 ) {
  row_split <- length(unique(targetFile$Target))
  column_split <- length(unique(targetFile$Target))
} else {
  row_split <- NULL
  column_split <- NULL
}

Heatmap(data.h, name = "expr", top_annotation = ha, cluster_rows = hr, cluster_columns = hc, row_split = row_split, column_split = column_split)
  
pdf(paste0(params$output_dir, "/", paste0(params$results_name, "_heatmap.pdf")), width = 8, height = 8)
Heatmap(data.h, name = "expr", top_annotation = ha, cluster_rows = hr, cluster_columns = hc, row_split = row_split, column_split = column_split, use_raster = FALSE)
dev.off()
```

```{r heatmap_interactive, warning = FALSE, echo = TRUE, message = FALSE, results = 'hide', fig.width = 12, fig.height = 10}
suppressMessages(library(heatmaply))

##### Generate heatmap (PLOTLY)
col_side_colors <- as.data.frame(targetFile[, "Target"])
colnames(col_side_colors) <- "Target"

col_side_palette <- targets.colour[[2]]
names(col_side_palette) <- col_side_colors$Target

p <- heatmaply(data.frame(data.h), Rowv = hr, Colv = rev(hc), k_col=1, k_row=1, colors = colorRampPalette(c("darkblue","darkblue","darkslateblue","darkslateblue","white","firebrick3","firebrick3","firebrick4","firebrick4"))(100), col_side_colors = col_side_colors, col_side_palette = col_side_palette, scale="row", trace="none", hide_colorbar = TRUE, fontsize_row = 8, fontsize_col = 8) %>%
layout(autosize = TRUE, width = 800, margin = list(l=150, r=50, b=150, t=50, pad=4), showlegend = FALSE)

##### Save the heatmap as html (PLOTLY)
saveWidgetFix(p, file = paste0(params$output_dir, "/", paste0(params$results_name, "_heatmap.html")), selfcontained = TRUE)

detach("package:heatmaply", unload=FALSE)
```

***

`r if ( runGOI ) { c("#### Genes of interest") }`

`r if ( runGOI ) { c("Heatmap presenting expression levels of **genes of interest** (*y-axis*) across all samples (*x-axis*).") }`

`r if ( runGOI ) { paste0("**<span style=\"color:#ff0000\">NOTE</span>**: expression data for ", length(goi_list[ goi_list %!in% rownames(data) ]), " genes were not available.") }`

`r if ( runGOI ) { paste0("<details>") }`
`r if ( runGOI ) { paste0("<summary>Input genes</summary>") }`
`r if ( runGOI ) { paste0("<font size=\"2\">") }`

*`r if ( runGOI ) { paste(goi_list[ goi_list %in% rownames(data) ], collapse = ", ") }`*

`r if ( runGOI ) { paste0("</font>") }`
`r if ( runGOI ) { paste0("</details>") }`

`r if ( runGOI ) { paste0("<details>") }`
`r if ( runGOI ) { paste0("<summary>Missing genes</summary>") }`
`r if ( runGOI ) { paste0("<font size=\"2\">") }`

*`r if ( runGOI ) { paste(goi_list[ goi_list %!in% rownames(data) ], collapse = ", ") }`*

`r if ( runGOI ) { paste0("</font>") }`
`r if ( runGOI ) { paste0("</details>") }`


```{r heatmap_goi, warning = FALSE, echo = TRUE, message = FALSE, results = 'hide', fig.width = 12, fig.height = 10, eval = runGOI}
##### Keep only genes of interest
data.h <- data.frame(data[ rownames(data) %in% goi_list,])

##### Prepare heatmap annotation (samples)
Target.col  <- targets.colour[[1]]
names(Target.col) <- sort(unique(targetFile$Target))
ha = HeatmapAnnotation(df = targetFile[, colnames(targetFile) %in% annotFeatures, drop = FALSE], col = list(Target = Target.col ))

##### Cluster genes
hc <- hclust(as.dist(1-cor(data.h, method="pearson")), method="ward.D2")

##### Cluster samples
hr <- hclust(as.dist(dist(data.h, method="euclidean")), method="ward.D2")

##### Generate heatmap (complexHeatmap)
if ( length(unique(targetFile$Target)) > 1 ) {
  row_split <- length(unique(targetFile$Target))
  column_split <- length(unique(targetFile$Target))
} else {
  row_split <- NULL
  column_split <- NULL
}

Heatmap(data.h, name = "expr", top_annotation = ha, cluster_rows = hr, cluster_columns = hc, row_split = row_split, column_split = column_split)
  
pdf(paste0(params$output_dir, "/", paste0(params$results_name, "_heatmap_goi.pdf")), width = 8, height = 8)
Heatmap(data.h, name = "expr", top_annotation = ha, cluster_rows = hr, cluster_columns = hc, row_split = row_split, column_split = column_split, use_raster = FALSE)
dev.off()
```

```{r heatmap_interactive_goi, warning = FALSE, echo = TRUE, message = FALSE, results = 'hide', fig.width = 12, fig.height = 10}
suppressMessages(library(heatmaply))

##### Generate heatmap (PLOTLY)
p <- heatmaply(data.frame(data.h), Rowv = hr, Colv = rev(hc), k_col=1, k_row=1, colors = colorRampPalette(c("darkblue","darkblue","darkslateblue","darkslateblue","white","firebrick3","firebrick3","firebrick4","firebrick4"))(100), col_side_colors = col_side_colors, col_side_palette = col_side_palette, scale="row", trace="none", hide_colorbar = TRUE, fontsize_row = 8, fontsize_col = 8) %>%
layout(autosize = TRUE, width = 800, margin = list(l=150, r=50, b=150, t=50, pad=4), showlegend = FALSE)

##### Save the heatmap as html (PLOTLY)
saveWidgetFix(p, file = paste0(params$output_dir, "/", paste0(params$results_name, "_heatmap_goi.html")), selfcontained = TRUE)

detach("package:heatmaply", unload=FALSE)
```

***

```{r write_data, comment = NA, message=FALSE, warning=FALSE}
##### Define the name base on input parameters
if ( params$filter ) {
  
  filtered <- "filtered"
} else {
  filtered <- ""
}
if ( params$log ) {
  
  logged <- "log"
} else {
  logged <- "noLog"
}
##### Save combined data into a file
write.table(y$norm, file=paste0(params$output_dir, "/", paste0(params$results_name, "_", filtered, "_", logged, ".txt")), sep="\t", quote=FALSE, row.names=TRUE, col.names=NA, append = FALSE)

##### Same for annotated genes
write.table(data, file=paste0(params$output_dir, "/", paste0(params$results_name, "_", filtered, "_", logged, "_annot.txt")), sep="\t", quote=FALSE, row.names=TRUE, col.names=NA, append = FALSE)
```

The combined `r params$transform` expression data were saved in **`r paste0(params$results_name, "_", filtered, "_", logged, ".txt")`**.

***

## Addendum

<details>
<summary>Parameters</summary>
<font size="2">

```{r params_info, comment = NA}
for ( i in 1:length(params) ) {
  cat(paste("Parameter: ", names(params)[i], "\nValue: ", paste(unlist(params[i]), collapse = ","), "\n\n", sep=""))
}
```

</font>
</details>

<details>
<summary>Session info</summary>
<font size="2">

```{r sessioninfo, comment = NA}
devtools::session_info()
```

</font>
</details>
